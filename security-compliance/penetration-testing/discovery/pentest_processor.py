"""
Penetration Test Result Processor
=================================

Processes results from penetration testing activities and converts them into
standardized vulnerability findings for integration with the vulnerability
remediation workflow system.

Supported Input Formats:
- Manual penetration test reports (JSON, XML, CSV)
- Automated penetration testing tool outputs
- Security assessment findings
- Red team exercise results
- Bug bounty submissions

Features:
- Intelligent parsing of various report formats
- Vulnerability validation and verification
- Risk context enhancement
- Evidence extraction and preservation
- Integration with existing vulnerability assessment framework
"""

import asyncio
import json
import csv
import xml.etree.ElementTree as ET
import logging
import re
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Union, AsyncGenerator
from dataclasses import dataclass, field
from pathlib import Path
from enum import Enum
import hashlib
import base64
import mimetypes

logger = logging.getLogger(__name__)

class PentestReportFormat(Enum):
    """Supported penetration test report formats"""
    JSON = "json"
    XML = "xml"
    CSV = "csv"
    NESSUS = "nessus"
    BURP = "burp"
    OWASP_ZAP = "owasp_zap"
    METASPLOIT = "metasploit"
    COBALT_STRIKE = "cobalt_strike"
    CUSTOM = "custom"

class FindingType(Enum):
    """Types of penetration test findings"""
    VULNERABILITY = "vulnerability"
    CONFIGURATION_ISSUE = "configuration_issue"
    POLICY_VIOLATION = "policy_violation"
    INFORMATION_DISCLOSURE = "information_disclosure"
    PRIVILEGE_ESCALATION = "privilege_escalation"
    AUTHENTICATION_BYPASS = "authentication_bypass"
    INJECTION_FLAW = "injection_flaw"
    CRYPTOGRAPHIC_WEAKNESS = "cryptographic_weakness"
    BUSINESS_LOGIC_FLAW = "business_logic_flaw"

class ValidationStatus(Enum):
    """Validation status for penetration test findings"""
    VALIDATED = "validated"
    SUSPECTED = "suspected"
    FALSE_POSITIVE = "false_positive"
    REQUIRES_VALIDATION = "requires_validation"
    CANNOT_VALIDATE = "cannot_validate"

@dataclass
class PentestFinding:
    """Standardized penetration test finding"""
    id: str
    title: str
    description: str
    finding_type: FindingType
    severity: str
    risk_rating: str
    cvss_score: float
    cvss_vector: Optional[str]
    affected_hosts: List[str]
    affected_services: List[str]
    vulnerability_class: str
    remediation_recommendation: str
    technical_details: str
    proof_of_concept: str
    references: List[str]
    cve_references: List[str]
    validation_status: ValidationStatus
    evidence: List[Dict[str, Any]] = field(default_factory=list)
    business_impact: str = ""
    likelihood: str = ""
    exploitability: str = ""
    tester_notes: str = ""
    test_methodology: str = ""
    tools_used: List[str] = field(default_factory=list)
    timestamps: Dict[str, str] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class PentestReport:
    """Complete penetration test report structure"""
    report_id: str
    title: str
    report_format: PentestReportFormat
    test_type: str
    test_scope: List[str]
    test_dates: Dict[str, str]
    tester_info: Dict[str, str]
    methodology: str
    tools_used: List[str]
    executive_summary: str
    findings: List[PentestFinding]
    remediation_timeline: Dict[str, str] = field(default_factory=dict)
    appendices: List[Dict[str, Any]] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)

class PentestResultProcessor:
    """
    Processes penetration testing results from various sources and formats
    """
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        self.parsers = {
            PentestReportFormat.JSON: self._parse_json_report,
            PentestReportFormat.XML: self._parse_xml_report,
            PentestReportFormat.CSV: self._parse_csv_report,
            PentestReportFormat.BURP: self._parse_burp_report,
            PentestReportFormat.OWASP_ZAP: self._parse_zap_report,
            PentestReportFormat.METASPLOIT: self._parse_metasploit_report,
        }
        
        # CVSS and severity mappings
        self.severity_mappings = {
            'critical': {'min_cvss': 9.0, 'max_cvss': 10.0},
            'high': {'min_cvss': 7.0, 'max_cvss': 8.9},
            'medium': {'min_cvss': 4.0, 'max_cvss': 6.9},
            'low': {'min_cvss': 0.1, 'max_cvss': 3.9},
            'info': {'min_cvss': 0.0, 'max_cvss': 0.0}
        }
        
        # Common vulnerability patterns for classification
        self.vuln_patterns = {
            'sql_injection': [
                r'sql\s+injection', r'sqli', r'union\s+select', r'or\s+1=1',
                r'database\s+error', r'mysql_', r'postgresql', r'oracle\s+error'
            ],
            'xss': [
                r'cross.?site\s+scripting', r'xss', r'<script', r'javascript:',
                r'onload\s*=', r'onerror\s*=', r'document\.cookie'
            ],
            'command_injection': [
                r'command\s+injection', r'os\s+command', r'shell\s+injection',
                r'system\(\)', r'exec\(\)', r'eval\(\)'
            ],
            'directory_traversal': [
                r'directory\s+traversal', r'path\s+traversal', r'\.\./',
                r'\.\.\\', r'file\s+inclusion'
            ],
            'authentication_bypass': [
                r'authentication\s+bypass', r'auth\s+bypass', r'login\s+bypass',
                r'session\s+fixation', r'weak\s+authentication'
            ]
        }
    
    async def process_pentest_report(self, 
                                   report_data: Union[str, bytes, Dict],
                                   report_format: PentestReportFormat,
                                   metadata: Optional[Dict[str, Any]] = None) -> PentestReport:
        """Process a penetration test report"""
        
        try:
            self.logger.info(f"Processing pentest report in {report_format.value} format")
            
            # Parse the report based on format
            if report_format in self.parsers:
                report = await self.parsers[report_format](report_data, metadata or {})
            else:
                raise ValueError(f"Unsupported report format: {report_format.value}")
            
            # Enhance findings with additional analysis
            for finding in report.findings:
                await self._enhance_finding(finding)
            
            self.logger.info(f"Processed pentest report with {len(report.findings)} findings")
            return report
            
        except Exception as e:
            self.logger.error(f"Failed to process pentest report: {e}")
            raise
    
    async def _parse_json_report(self, data: Union[str, Dict], metadata: Dict) -> PentestReport:
        """Parse JSON format penetration test report"""
        
        if isinstance(data, str):
            report_data = json.loads(data)
        else:
            report_data = data
        
        # Extract report metadata
        report_id = report_data.get('report_id', self._generate_report_id())
        title = report_data.get('title', 'Penetration Test Report')
        
        # Extract test information
        test_info = report_data.get('test_info', {})
        test_type = test_info.get('type', 'general')
        test_scope = test_info.get('scope', [])
        test_dates = test_info.get('dates', {})
        tester_info = test_info.get('tester', {})
        methodology = test_info.get('methodology', '')
        tools_used = test_info.get('tools', [])
        
        # Parse findings
        findings = []
        findings_data = report_data.get('findings', [])
        
        for idx, finding_data in enumerate(findings_data):
            finding = await self._parse_json_finding(finding_data, idx)
            if finding:
                findings.append(finding)
        
        return PentestReport(
            report_id=report_id,
            title=title,
            report_format=PentestReportFormat.JSON,
            test_type=test_type,
            test_scope=test_scope,
            test_dates=test_dates,
            tester_info=tester_info,
            methodology=methodology,
            tools_used=tools_used,
            executive_summary=report_data.get('executive_summary', ''),
            findings=findings,
            remediation_timeline=report_data.get('remediation_timeline', {}),
            metadata=metadata
        )
    
    async def _parse_json_finding(self, finding_data: Dict, index: int) -> Optional[PentestFinding]:
        """Parse individual JSON finding"""
        
        try:
            finding_id = finding_data.get('id', f"finding_{index}")
            title = finding_data.get('title', f'Finding {index + 1}')
            
            # Determine finding type
            finding_type = self._classify_finding_type(
                title + ' ' + finding_data.get('description', '')
            )
            
            # Parse severity and CVSS
            severity = finding_data.get('severity', 'medium').lower()
            cvss_score = finding_data.get('cvss_score', 0.0)
            if cvss_score == 0.0:
                cvss_score = self._estimate_cvss_from_severity(severity)
            
            # Parse affected assets
            affected_hosts = finding_data.get('affected_hosts', [])
            affected_services = finding_data.get('affected_services', [])
            
            # Parse evidence
            evidence = []
            evidence_data = finding_data.get('evidence', [])
            for evidence_item in evidence_data:
                if isinstance(evidence_item, dict):
                    evidence.append(evidence_item)
                elif isinstance(evidence_item, str):
                    evidence.append({
                        'type': 'text',
                        'content': evidence_item,
                        'timestamp': datetime.now(timezone.utc).isoformat()
                    })
            
            # Determine validation status
            validation_status = ValidationStatus.REQUIRES_VALIDATION
            if finding_data.get('validated', False):
                validation_status = ValidationStatus.VALIDATED
            elif finding_data.get('false_positive', False):
                validation_status = ValidationStatus.FALSE_POSITIVE
            
            return PentestFinding(
                id=finding_id,
                title=title,
                description=finding_data.get('description', ''),
                finding_type=finding_type,
                severity=severity,
                risk_rating=finding_data.get('risk_rating', severity.title()),
                cvss_score=cvss_score,
                cvss_vector=finding_data.get('cvss_vector'),
                affected_hosts=affected_hosts,
                affected_services=affected_services,
                vulnerability_class=finding_data.get('vulnerability_class', ''),
                remediation_recommendation=finding_data.get('remediation', ''),
                technical_details=finding_data.get('technical_details', ''),
                proof_of_concept=finding_data.get('proof_of_concept', ''),
                references=finding_data.get('references', []),
                cve_references=finding_data.get('cve_references', []),
                validation_status=validation_status,
                evidence=evidence,
                business_impact=finding_data.get('business_impact', ''),
                likelihood=finding_data.get('likelihood', ''),
                exploitability=finding_data.get('exploitability', ''),
                tester_notes=finding_data.get('tester_notes', ''),
                test_methodology=finding_data.get('test_methodology', ''),
                tools_used=finding_data.get('tools_used', []),
                timestamps=finding_data.get('timestamps', {}),
                metadata=finding_data.get('metadata', {})
            )
            
        except Exception as e:
            self.logger.error(f"Failed to parse JSON finding {index}: {e}")
            return None
    
    async def _parse_burp_report(self, data: Union[str, bytes], metadata: Dict) -> PentestReport:
        """Parse Burp Suite report"""
        
        if isinstance(data, bytes):
            xml_content = data.decode('utf-8')
        else:
            xml_content = data
        
        root = ET.fromstring(xml_content)
        
        # Extract report metadata
        report_id = self._generate_report_id()
        title = "Burp Suite Security Assessment"
        
        findings = []
        
        # Parse Burp issues
        for issue in root.findall('.//issue'):
            finding = await self._parse_burp_issue(issue, len(findings))
            if finding:
                findings.append(finding)
        
        return PentestReport(
            report_id=report_id,
            title=title,
            report_format=PentestReportFormat.BURP,
            test_type="web_application",
            test_scope=[],
            test_dates={},
            tester_info={"tool": "Burp Suite"},
            methodology="Automated Web Application Security Testing",
            tools_used=["Burp Suite"],
            executive_summary="",
            findings=findings,
            metadata=metadata
        )
    
    async def _parse_burp_issue(self, issue_element, index: int) -> Optional[PentestFinding]:
        """Parse individual Burp Suite issue"""
        
        try:
            # Extract basic information
            name = self._get_element_text(issue_element, 'name')
            host = self._get_element_text(issue_element, 'host')
            path = self._get_element_text(issue_element, 'path')
            location = self._get_element_text(issue_element, 'location')
            
            finding_id = f"burp_{index}_{hashlib.md5((name + host + path).encode()).hexdigest()[:8]}"
            
            # Extract severity
            severity = self._get_element_text(issue_element, 'severity').lower()
            confidence = self._get_element_text(issue_element, 'confidence').lower()
            
            # Extract details
            background = self._get_element_text(issue_element, 'issueBackground')
            detail = self._get_element_text(issue_element, 'issueDetail')
            remediation = self._get_element_text(issue_element, 'remediationBackground')
            
            # Extract request/response evidence
            evidence = []
            
            # HTTP messages
            for request in issue_element.findall('.//request'):
                if request.text:
                    evidence.append({
                        'type': 'http_request',
                        'content': base64.b64decode(request.text).decode('utf-8', errors='ignore'),
                        'timestamp': datetime.now(timezone.utc).isoformat()
                    })
            
            for response in issue_element.findall('.//response'):
                if response.text:
                    evidence.append({
                        'type': 'http_response',
                        'content': base64.b64decode(response.text).decode('utf-8', errors='ignore'),
                        'timestamp': datetime.now(timezone.utc).isoformat()
                    })
            
            # Determine validation status based on confidence
            validation_status = ValidationStatus.SUSPECTED
            if confidence == 'certain':
                validation_status = ValidationStatus.VALIDATED
            elif confidence == 'firm':
                validation_status = ValidationStatus.SUSPECTED
            else:
                validation_status = ValidationStatus.REQUIRES_VALIDATION
            
            # Classify finding type
            finding_type = self._classify_finding_type(name + ' ' + background)
            
            return PentestFinding(
                id=finding_id,
                title=name,
                description=f"{background}\n\n{detail}",
                finding_type=finding_type,
                severity=severity,
                risk_rating=severity.title(),
                cvss_score=self._estimate_cvss_from_severity(severity),
                cvss_vector=None,
                affected_hosts=[host] if host else [],
                affected_services=[],
                vulnerability_class=name,
                remediation_recommendation=remediation,
                technical_details=detail,
                proof_of_concept=location,
                references=[],
                cve_references=[],
                validation_status=validation_status,
                evidence=evidence,
                business_impact="",
                likelihood="",
                exploitability="",
                tester_notes=f"Confidence: {confidence}",
                test_methodology="Burp Suite Automated Scanning",
                tools_used=["Burp Suite"],
                timestamps={
                    'discovered': datetime.now(timezone.utc).isoformat()
                },
                metadata={
                    'burp_confidence': confidence,
                    'burp_path': path,
                    'burp_location': location
                }
            )
            
        except Exception as e:
            self.logger.error(f"Failed to parse Burp issue {index}: {e}")
            return None
    
    async def _parse_zap_report(self, data: Union[str, bytes], metadata: Dict) -> PentestReport:
        """Parse OWASP ZAP report"""
        # Similar implementation to Burp but for ZAP XML format
        # Placeholder implementation
        return PentestReport(
            report_id=self._generate_report_id(),
            title="OWASP ZAP Security Assessment",
            report_format=PentestReportFormat.OWASP_ZAP,
            test_type="web_application",
            test_scope=[],
            test_dates={},
            tester_info={"tool": "OWASP ZAP"},
            methodology="Automated Web Application Security Testing",
            tools_used=["OWASP ZAP"],
            executive_summary="",
            findings=[],
            metadata=metadata
        )
    
    async def _parse_xml_report(self, data: Union[str, bytes], metadata: Dict) -> PentestReport:
        """Parse generic XML format report"""
        # Generic XML parsing implementation
        # This would be customized based on specific XML schema
        return PentestReport(
            report_id=self._generate_report_id(),
            title="XML Security Report",
            report_format=PentestReportFormat.XML,
            test_type="general",
            test_scope=[],
            test_dates={},
            tester_info={},
            methodology="",
            tools_used=[],
            executive_summary="",
            findings=[],
            metadata=metadata
        )
    
    async def _parse_csv_report(self, data: Union[str, bytes], metadata: Dict) -> PentestReport:
        """Parse CSV format report"""
        
        if isinstance(data, bytes):
            csv_content = data.decode('utf-8')
        else:
            csv_content = data
        
        findings = []
        reader = csv.DictReader(csv_content.splitlines())
        
        for idx, row in enumerate(reader):
            finding = await self._parse_csv_finding(row, idx)
            if finding:
                findings.append(finding)
        
        return PentestReport(
            report_id=self._generate_report_id(),
            title="CSV Security Report",
            report_format=PentestReportFormat.CSV,
            test_type="general",
            test_scope=[],
            test_dates={},
            tester_info={},
            methodology="",
            tools_used=[],
            executive_summary="",
            findings=findings,
            metadata=metadata
        )
    
    async def _parse_csv_finding(self, row: Dict, index: int) -> Optional[PentestFinding]:
        """Parse individual CSV finding"""
        
        try:
            # Map common CSV column names
            title = row.get('title') or row.get('name') or row.get('vulnerability') or f'Finding {index + 1}'
            description = row.get('description') or row.get('details') or ''
            severity = (row.get('severity') or row.get('risk') or 'medium').lower()
            host = row.get('host') or row.get('target') or row.get('ip') or ''
            
            finding_id = f"csv_{index}_{hashlib.md5((title + host).encode()).hexdigest()[:8]}"
            
            return PentestFinding(
                id=finding_id,
                title=title,
                description=description,
                finding_type=self._classify_finding_type(title + ' ' + description),
                severity=severity,
                risk_rating=severity.title(),
                cvss_score=self._estimate_cvss_from_severity(severity),
                cvss_vector=row.get('cvss_vector'),
                affected_hosts=[host] if host else [],
                affected_services=[],
                vulnerability_class=title,
                remediation_recommendation=row.get('remediation') or row.get('solution') or '',
                technical_details=row.get('technical_details') or '',
                proof_of_concept=row.get('proof_of_concept') or row.get('poc') or '',
                references=row.get('references', '').split(',') if row.get('references') else [],
                cve_references=row.get('cve', '').split(',') if row.get('cve') else [],
                validation_status=ValidationStatus.REQUIRES_VALIDATION,
                evidence=[],
                business_impact=row.get('business_impact') or '',
                likelihood=row.get('likelihood') or '',
                exploitability=row.get('exploitability') or '',
                tester_notes=row.get('notes') or '',
                test_methodology="",
                tools_used=[],
                timestamps={
                    'discovered': datetime.now(timezone.utc).isoformat()
                },
                metadata={k: v for k, v in row.items() if v}
            )
            
        except Exception as e:
            self.logger.error(f"Failed to parse CSV finding {index}: {e}")
            return None
    
    async def _parse_metasploit_report(self, data: Union[str, bytes], metadata: Dict) -> PentestReport:
        """Parse Metasploit report"""
        # Placeholder for Metasploit report parsing
        return PentestReport(
            report_id=self._generate_report_id(),
            title="Metasploit Assessment",
            report_format=PentestReportFormat.METASPLOIT,
            test_type="penetration_test",
            test_scope=[],
            test_dates={},
            tester_info={"tool": "Metasploit"},
            methodology="Exploitation Framework Testing",
            tools_used=["Metasploit"],
            executive_summary="",
            findings=[],
            metadata=metadata
        )
    
    def _classify_finding_type(self, text: str) -> FindingType:
        """Classify finding type based on text content"""
        
        text_lower = text.lower()
        
        # Check for specific vulnerability patterns
        for vuln_type, patterns in self.vuln_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_lower):
                    if vuln_type in ['sql_injection', 'xss', 'command_injection']:
                        return FindingType.INJECTION_FLAW
                    elif vuln_type == 'authentication_bypass':
                        return FindingType.AUTHENTICATION_BYPASS
                    elif vuln_type == 'directory_traversal':
                        return FindingType.VULNERABILITY
        
        # Check for other finding types
        if any(keyword in text_lower for keyword in ['privilege', 'escalation', 'elevation']):
            return FindingType.PRIVILEGE_ESCALATION
        elif any(keyword in text_lower for keyword in ['information', 'disclosure', 'leak']):
            return FindingType.INFORMATION_DISCLOSURE
        elif any(keyword in text_lower for keyword in ['configuration', 'misconfiguration', 'setting']):
            return FindingType.CONFIGURATION_ISSUE
        elif any(keyword in text_lower for keyword in ['policy', 'compliance', 'violation']):
            return FindingType.POLICY_VIOLATION
        elif any(keyword in text_lower for keyword in ['crypto', 'encryption', 'ssl', 'tls', 'certificate']):
            return FindingType.CRYPTOGRAPHIC_WEAKNESS
        elif any(keyword in text_lower for keyword in ['business', 'logic', 'workflow']):
            return FindingType.BUSINESS_LOGIC_FLAW
        
        return FindingType.VULNERABILITY
    
    def _estimate_cvss_from_severity(self, severity: str) -> float:
        """Estimate CVSS score from severity level"""
        severity_lower = severity.lower()
        
        if severity_lower == 'critical':
            return 9.5
        elif severity_lower == 'high':
            return 7.5
        elif severity_lower == 'medium':
            return 5.0
        elif severity_lower == 'low':
            return 2.5
        else:
            return 0.0
    
    async def _enhance_finding(self, finding: PentestFinding):
        """Enhance finding with additional analysis"""
        
        # Add CVE references if missing
        if not finding.cve_references:
            finding.cve_references = await self._search_cve_references(finding)
        
        # Enhance business impact if missing
        if not finding.business_impact:
            finding.business_impact = self._assess_business_impact(finding)
        
        # Enhance exploitability assessment
        if not finding.exploitability:
            finding.exploitability = self._assess_exploitability(finding)
    
    async def _search_cve_references(self, finding: PentestFinding) -> List[str]:
        """Search for CVE references related to the finding"""
        # Placeholder implementation - would integrate with CVE databases
        return []
    
    def _assess_business_impact(self, finding: PentestFinding) -> str:
        """Assess business impact of the finding"""
        
        severity_impact = {
            'critical': 'High - Could result in complete system compromise',
            'high': 'Medium-High - Could lead to significant data breach',
            'medium': 'Medium - Could impact system availability or data integrity',
            'low': 'Low - Limited impact on business operations',
            'info': 'Minimal - Informational finding with low business impact'
        }
        
        return severity_impact.get(finding.severity, 'Unknown business impact')
    
    def _assess_exploitability(self, finding: PentestFinding) -> str:
        """Assess exploitability of the finding"""
        
        exploitability_factors = {
            'high': ['remote', 'unauthenticated', 'public exploit'],
            'medium': ['authenticated', 'network access', 'known technique'],
            'low': ['local access', 'complex exploit', 'specialized knowledge']
        }
        
        text = (finding.title + ' ' + finding.description).lower()
        
        for level, factors in exploitability_factors.items():
            if any(factor in text for factor in factors):
                return level.title()
        
        return 'Unknown'
    
    def _generate_report_id(self) -> str:
        """Generate unique report ID"""
        timestamp = datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')
        random_suffix = hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8]
        return f"pentest_{timestamp}_{random_suffix}"
    
    def _get_element_text(self, parent, element_name: str) -> str:
        """Safely get text from XML element"""
        element = parent.find(element_name)
        return element.text if element is not None and element.text else ""
    
    async def discover_vulnerabilities(self, 
                                     targets: List[str], 
                                     scan_config: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """
        Discovery interface for integration with vulnerability discovery engine
        Processes pentest reports and returns standardized vulnerability findings
        """
        
        findings = []
        
        if not scan_config:
            self.logger.warning("No scan config provided for pentest processing")
            return findings
        
        # Extract report data and format from config
        report_data = scan_config.get('report_data')
        report_format = scan_config.get('report_format', 'json')
        
        if not report_data:
            self.logger.warning("No report data provided in scan config")
            return findings
        
        try:
            # Parse the report format
            format_enum = PentestReportFormat(report_format.lower())
            
            # Process the report
            report = await self.process_pentest_report(
                report_data, format_enum, scan_config.get('metadata', {})
            )
            
            # Convert findings to standardized format
            for finding in report.findings:
                standardized_finding = {
                    'id': finding.id,
                    'title': finding.title,
                    'description': finding.description,
                    'severity': finding.severity,
                    'cvss_score': finding.cvss_score,
                    'cve_id': finding.cve_references[0] if finding.cve_references else None,
                    'affected_hosts': finding.affected_hosts,
                    'affected_services': finding.affected_services,
                    'remediation': finding.remediation_recommendation,
                    'scanner': 'penetration_test',
                    'validated': finding.validation_status == ValidationStatus.VALIDATED,
                    'false_positive': finding.validation_status == ValidationStatus.FALSE_POSITIVE,
                    'exploit_available': finding.exploitability in ['high', 'medium'],
                    'evidence': finding.evidence,
                    'references': finding.references,
                    'business_impact': finding.business_impact,
                    'technical_details': finding.technical_details,
                    'proof_of_concept': finding.proof_of_concept,
                    'asset': {
                        'hosts': finding.affected_hosts,
                        'services': finding.affected_services
                    },
                    'metadata': {
                        'finding_type': finding.finding_type.value,
                        'validation_status': finding.validation_status.value,
                        'test_methodology': finding.test_methodology,
                        'tools_used': finding.tools_used,
                        'tester_notes': finding.tester_notes,
                        'original_metadata': finding.metadata
                    }
                }
                findings.append(standardized_finding)
            
            self.logger.info(f"Processed {len(findings)} pentest findings")
            
        except Exception as e:
            self.logger.error(f"Error processing pentest report: {e}")
            raise
        
        return findings