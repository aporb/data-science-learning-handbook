"""
Penetration Testing Integration Layer
===================================

Integration and workflow layer that connects penetration testing reporting
with existing compliance infrastructure, providing automated workflows,
report distribution, remediation tracking, and external system integration.

Key Features:
- Integration with existing compliance reporting
- Automated report distribution and approval workflows
- Remediation tracking integration
- Scheduling and recurring test reporting
- API integration with external systems
- Real-time notification and alerting
- Compliance framework mapping

Integration Points:  
- Enhanced monitoring system for real-time integration
- Compliance documentation framework for unified reporting
- Risk assessment and analytics for risk correlation
- Multi-classification engine for secure integration
- Audit system for comprehensive audit trails
- RBAC system for access-controlled integration

Classification: UNCLASSIFIED//FOR OFFICIAL USE ONLY
Version: 1.0 - Penetration Testing Integration Layer
Author: Red Team Operations
Date: 2025-07-28
"""

import asyncio
import json
import logging
import time
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Any, Tuple, Set, Union, AsyncGenerator, Callable
from uuid import UUID, uuid4
from dataclasses import dataclass, field, asdict
from enum import Enum
from concurrent.futures import ThreadPoolExecutor
from collections import defaultdict, deque
import aiofiles
import aiohttp
from threading import Lock
import numpy as np
from pathlib import Path
import sqlite3
import smtplib
from email.mime.text import MIMTPText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
import schedule
import requests

# Import from existing infrastructure
import sys
sys.path.append(str(Path(__file__).parent.parent.parent))

try:
    from compliance.reporting.automated_reporting_engine import AutomatedReportingEngine
    from audits.enhanced_monitoring_system import EnhancedMonitoringSystem
    from multi_classification.enhanced_classification_engine import EnhancedClassificationEngine
    from rbac.rbac_system import RBACSystem
except ImportError as e:
    logger.warning(f"Could not import existing infrastructure components: {e}")

# Import from our pentest modules
from ..reports.report_generation_engine import ReportGenerationEngine, PentestReport, ReportFormat
from ..metrics.analytics_dashboard import PentestAnalyticsDashboard, MetricType
from ..evidence.evidence_collector import EvidenceCollector, EvidenceType

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class IntegrationType(Enum):
    """Types of system integrations."""
    COMPLIANCE_REPORTING = "compliance_reporting"
    MONITORING_SYSTEM = "monitoring_system"
    TICKETING_SYSTEM = "ticketing_system"
    EMAIL_NOTIFICATION = "email_notification"
    EXTERNAL_API = "external_api"
    DATABASE_SYNC = "database_sync"
    DASHBOARD_INTEGRATION = "dashboard_integration"

class WorkflowStatus(Enum):
    """Workflow execution status."""
    PENDING = "pending"
    RUNNING = "running" 
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

class NotificationChannel(Enum):
    """Notification delivery channels."""
    EMAIL = "email"
    SLACK = "slack"
    TEAMS = "teams"
    WEBHOOK = "webhook"
    SMS = "sms"

@dataclass
class IntegrationConfig:
    """Configuration for system integrations."""
    id: str = field(default_factory=lambda: str(uuid4()))
    name: str = ""
    type: IntegrationType = IntegrationType.EMAIL_NOTIFICATION
    enabled: bool = True
    endpoint: str = ""
    credentials: Dict[str, str] = field(default_factory=dict)
    settings: Dict[str, Any] = field(default_factory=dict)
    retry_attempts: int = 3
    timeout: int = 30
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    last_updated: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

@dataclass
class WorkflowStep:
    """Individual workflow step."""
    id: str = field(default_factory=lambda: str(uuid4()))
    name: str = ""
    description: str = ""
    action_type: str = ""  # generate_report, send_notification, create_ticket, etc.
    parameters: Dict[str, Any] = field(default_factory=dict)
    dependencies: List[str] = field(default_factory=list)
    timeout: int = 300  # 5 minutes default
    retry_attempts: int = 3
    condition: str = ""  # Optional condition for step execution

@dataclass
class Workflow:
    """Automated workflow definition."""
    id: str = field(default_factory=lambda: str(uuid4()))
    name: str = ""
    description: str = ""
    trigger: str = ""  # test_completed, finding_discovered, scheduled, etc.
    steps: List[WorkflowStep] = field(default_factory=list)
    enabled: bool = True
    schedule: str = ""  # Cron-like schedule for recurring workflows
    created_by: str = ""
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    last_executed: Optional[datetime] = None
    execution_count: int = 0

@dataclass
class WorkflowExecution:
    """Workflow execution tracking."""
    id: str = field(default_factory=lambda: str(uuid4()))
    workflow_id: str = ""
    status: WorkflowStatus = WorkflowStatus.PENDING
    started_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    completed_at: Optional[datetime] = None
    steps_executed: List[str] = field(default_factory=list)
    steps_failed: List[str] = field(default_factory=list)
    error_message: str = ""
    results: Dict[str, Any] = field(default_factory=dict)
    triggered_by: str = ""

@dataclass
class RemediationTask:
    """Remediation tracking task."""
    id: str = field(default_factory=lambda: str(uuid4()))
    finding_id: str = ""
    title: str = ""
    description: str = ""
    priority: str = "Medium"
    assigned_to: str = ""
    assigned_team: str = ""
    status: str = "Open"
    due_date: Optional[datetime] = None
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    estimated_effort: str = ""
    actual_effort: str = ""
    remediation_notes: str = ""
    verification_required: bool = True
    verification_status: str = "Pending"
    external_ticket_id: str = ""

class PentestIntegrationLayer:
    """
    Comprehensive integration layer for penetration testing workflows.
    
    This layer connects all penetration testing components with existing
    infrastructure and provides automated workflows, notifications, and
    external system integrations.
    """
    
    def __init__(self, config_path: str = None):
        """Initialize the integration layer."""
        self.config_path = Path(config_path) if config_path else Path(__file__).parent / "integration_config.json"
        self.db_path = Path(__file__).parent / "integration.db"
        
        # Initialize components
        self.report_engine = ReportGenerationEngine()
        self.analytics_dashboard = PentestAnalyticsDashboard()
        self.evidence_collector = EvidenceCollector()
        
        # Integration configurations
        self.integrations: Dict[str, IntegrationConfig] = {}
        self.workflows: Dict[str, Workflow] = {}
        self.active_executions: Dict[str, WorkflowExecution] = {}
        
        # Thread pool for async operations
        self.executor = ThreadPoolExecutor(max_workers=10)
        
        # Initialize database and load configuration
        asyncio.create_task(self._initialize_system())
        
        logger.info("Penetration Testing Integration Layer initialized")
    
    async def _initialize_system(self):
        """Initialize the integration system."""
        await self._initialize_database()
        await self._load_configuration()
        await self._setup_integrations()
        self._start_scheduler()
    
    async def _initialize_database(self):
        """Initialize the integration database."""
        try:
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            # Integration configurations table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS integration_configs (
                    id TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    type TEXT NOT NULL,
                    enabled BOOLEAN,
                    endpoint TEXT,
                    credentials TEXT,
                    settings TEXT,
                    retry_attempts INTEGER,
                    timeout INTEGER,
                    created_at DATETIME,
                    last_updated DATETIME
                )
            """)
            
            # Workflows table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS workflows (
                    id TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    description TEXT,
                    trigger_type TEXT,
                    steps TEXT,
                    enabled BOOLEAN,
                    schedule_expression TEXT,
                    created_by TEXT,
                    created_at DATETIME,
                    last_executed DATETIME,
                    execution_count INTEGER
                )
            """)
            
            # Workflow executions table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS workflow_executions (
                    id TEXT PRIMARY KEY,
                    workflow_id TEXT NOT NULL,
                    status TEXT NOT NULL,
                    started_at DATETIME,
                    completed_at DATETIME,
                    steps_executed TEXT,
                    steps_failed TEXT,
                    error_message TEXT,
                    results TEXT,
                    triggered_by TEXT,
                    FOREIGN KEY (workflow_id) REFERENCES workflows (id)
                )
            """)
            
            # Remediation tasks table
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS remediation_tasks (
                    id TEXT PRIMARY KEY,
                    finding_id TEXT NOT NULL,
                    title TEXT NOT NULL,
                    description TEXT,
                    priority TEXT,
                    assigned_to TEXT,
                    assigned_team TEXT,
                    status TEXT,
                    due_date DATETIME,
                    created_at DATETIME,
                    updated_at DATETIME,
                    estimated_effort TEXT,
                    actual_effort TEXT,
                    remediation_notes TEXT,
                    verification_required BOOLEAN,
                    verification_status TEXT,
                    external_ticket_id TEXT
                )
            """)
            
            # Create indexes
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_executions_workflow_id ON workflow_executions(workflow_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_executions_status ON workflow_executions(status)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_remediation_finding_id ON remediation_tasks(finding_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_remediation_status ON remediation_tasks(status)")
            
            conn.commit()
            conn.close()
            
            logger.info("Integration database initialized successfully")
            
        except Exception as e:
            logger.error(f"Error initializing integration database: {str(e)}")
            raise
    
    async def _load_configuration(self):
        """Load integration configuration from file."""
        try:
            if self.config_path.exists():
                async with aiofiles.open(self.config_path, 'r') as f:
                    config_data = json.loads(await f.read())
                
                # Load integration configurations
                for integration_data in config_data.get('integrations', []):
                    integration = IntegrationConfig(**integration_data)
                    self.integrations[integration.id] = integration
                
                # Load workflows
                for workflow_data in config_data.get('workflows', []):
                    # Convert steps from dict to WorkflowStep objects
                    steps = [WorkflowStep(**step_data) for step_data in workflow_data.get('steps', [])]
                    workflow_data['steps'] = steps
                    workflow = Workflow(**workflow_data)
                    self.workflows[workflow.id] = workflow
                
                logger.info(f"Configuration loaded: {len(self.integrations)} integrations, {len(self.workflows)} workflows")
            else:
                # Create default configuration
                await self._create_default_configuration()
                
        except Exception as e:
            logger.error(f"Error loading configuration: {str(e)}")
            await self._create_default_configuration()
    
    async def _create_default_configuration(self):
        """Create default integration configuration."""
        try:
            # Default email integration
            email_integration = IntegrationConfig(
                name="Default Email Notification",
                type=IntegrationType.EMAIL_NOTIFICATION,
                endpoint="smtp.example.com:587",
                settings={
                    "use_tls": True,
                    "from_address": "pentest-reports@example.com",
                    "recipients": ["security-team@example.com"]
                }
            )
            self.integrations[email_integration.id] = email_integration
            
            # Default compliance reporting workflow
            compliance_workflow = Workflow(
                name="Compliance Report Generation",
                description="Generate and distribute compliance reports after test completion",
                trigger="test_completed",
                steps=[
                    WorkflowStep(
                        name="Generate PDF Report",
                        action_type="generate_report",
                        parameters={"format": "pdf", "include_executive_summary": True}
                    ),
                    WorkflowStep(
                        name="Send Email Notification",
                        action_type="send_notification",
                        parameters={"channel": "email", "template": "test_completion"}
                    )
                ]
            )
            self.workflows[compliance_workflow.id] = compliance_workflow
            
            # Save default configuration
            await self._save_configuration()
            
            logger.info("Default configuration created")
            
        except Exception as e:
            logger.error(f"Error creating default configuration: {str(e)}")
            raise
    
    async def _save_configuration(self):
        """Save current configuration to file."""
        try:
            config_data = {
                'integrations': [asdict(integration) for integration in self.integrations.values()],
                'workflows': []
            }
            
            # Convert workflows to serializable format
            for workflow in self.workflows.values():
                workflow_dict = asdict(workflow)
                # Convert steps to dictionaries
                workflow_dict['steps'] = [asdict(step) for step in workflow.steps]
                config_data['workflows'].append(workflow_dict)
            
            async with aiofiles.open(self.config_path, 'w') as f:
                await f.write(json.dumps(config_data, indent=2, default=str))
            
            logger.debug("Configuration saved")
            
        except Exception as e:
            logger.error(f"Error saving configuration: {str(e)}")
            raise
    
    async def _setup_integrations(self):
        """Setup and validate integrations."""
        for integration in self.integrations.values():
            if integration.enabled:
                try:
                    await self._validate_integration(integration)
                    logger.info(f"Integration validated: {integration.name}")
                except Exception as e:
                    logger.warning(f"Integration validation failed for {integration.name}: {str(e)}")
    
    async def _validate_integration(self, integration: IntegrationConfig):
        """Validate an integration configuration."""
        if integration.type == IntegrationType.EMAIL_NOTIFICATION:
            await self._validate_email_integration(integration)
        elif integration.type == IntegrationType.EXTERNAL_API:
            await self._validate_api_integration(integration)
        # Add more integration validations as needed
    
    async def _validate_email_integration(self, integration: IntegrationConfig):
        """Validate email integration."""
        try:
            # Parse SMTP settings
            endpoint_parts = integration.endpoint.split(':')
            smtp_server = endpoint_parts[0]
            smtp_port = int(endpoint_parts[1]) if len(endpoint_parts) > 1 else 587
            
            # Test SMTP connection (without actually sending)
            server = smtplib.SMTP(smtp_server, smtp_port)
            if integration.settings.get('use_tls', True):
                server.starttls()
            
            # Test authentication if credentials provided
            if integration.credentials.get('username') and integration.credentials.get('password'):
                server.login(integration.credentials['username'], integration.credentials['password'])
            
            server.quit()
            logger.debug(f"Email integration validated: {integration.name}")
            
        except Exception as e:
            raise Exception(f"Email integration validation failed: {str(e)}")
    
    async def _validate_api_integration(self, integration: IntegrationConfig):
        """Validate API integration."""
        try:
            # Test API endpoint
            timeout = integration.timeout
            headers = integration.settings.get('headers', {})
            
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=timeout)) as session:
                async with session.get(integration.endpoint, headers=headers) as response:
                    if response.status >= 400:
                        raise Exception(f"API returned status {response.status}")
            
            logger.debug(f"API integration validated: {integration.name}")
            
        except Exception as e:
            raise Exception(f"API integration validation failed: {str(e)}")
    
    def _start_scheduler(self):
        """Start the workflow scheduler."""
        # Setup scheduled workflows
        for workflow in self.workflows.values():
            if workflow.enabled and workflow.schedule:
                try:
                    schedule.every().day.at(workflow.schedule).do(
                        self._run_scheduled_workflow, workflow.id
                    )
                    logger.info(f"Scheduled workflow: {workflow.name} at {workflow.schedule}")
                except Exception as e:
                    logger.warning(f"Failed to schedule workflow {workflow.name}: {str(e)}")
        
        # Start scheduler thread
        def run_scheduler():
            while True:
                schedule.run_pending()
                time.sleep(60)  # Check every minute
        
        from threading import Thread
        scheduler_thread = Thread(target=run_scheduler, daemon=True)
        scheduler_thread.start()
        
        logger.info("Workflow scheduler started")
    
    def _run_scheduled_workflow(self, workflow_id: str):
        """Run a scheduled workflow."""
        asyncio.create_task(self.execute_workflow(workflow_id, triggered_by="scheduler"))
    
    async def execute_workflow(self, workflow_id: str, triggered_by: str = "", context: Dict[str, Any] = None) -> WorkflowExecution:
        """
        Execute a workflow.
        
        Args:
            workflow_id: ID of the workflow to execute
            triggered_by: What/who triggered the workflow
            context: Additional context data for the workflow
            
        Returns:
            Workflow execution record
        """
        try:
            workflow = self.workflows.get(workflow_id)
            if not workflow:
                raise ValueError(f"Workflow not found: {workflow_id}")
            
            if not workflow.enabled:
                raise ValueError(f"Workflow is disabled: {workflow.name}")
            
            # Create execution record
            execution = WorkflowExecution(
                workflow_id=workflow_id,
                triggered_by=triggered_by,
                status=WorkflowStatus.RUNNING
            )
            
            self.active_executions[execution.id] = execution
            
            logger.info(f"Starting workflow execution: {workflow.name}")
            
            try:
                # Execute workflow steps
                context = context or {}
                
                for step in workflow.steps:
                    # Check dependencies
                    if step.dependencies:
                        for dep_step_id in step.dependencies:
                            if dep_step_id not in execution.steps_executed:
                                raise Exception(f"Dependency not met: {dep_step_id}")
                    
                    # Execute step
                    logger.info(f"Executing step: {step.name}")
                    step_result = await self._execute_workflow_step(step, context)
                    
                    execution.steps_executed.append(step.id)
                    execution.results[step.id] = step_result
                    
                    # Update context with step results
                    context.update(step_result)
                
                # Mark as completed
                execution.status = WorkflowStatus.COMPLETED
                execution.completed_at = datetime.now(timezone.utc)
                
                # Update workflow statistics
                workflow.last_executed = execution.completed_at
                workflow.execution_count += 1
                
                logger.info(f"Workflow completed successfully: {workflow.name}")
                
            except Exception as e:
                execution.status = WorkflowStatus.FAILED
                execution.error_message = str(e)
                execution.completed_at = datetime.now(timezone.utc)
                logger.error(f"Workflow execution failed: {workflow.name} - {str(e)}")
                raise
            
            finally:
                # Store execution record
                await self._store_workflow_execution(execution)
                
                # Remove from active executions
                if execution.id in self.active_executions:
                    del self.active_executions[execution.id]
            
            return execution
            
        except Exception as e:
            logger.error(f"Error executing workflow: {str(e)}")
            raise
    
    async def _execute_workflow_step(self, step: WorkflowStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute a single workflow step."""
        try:
            if step.action_type == "generate_report":
                return await self._execute_generate_report_step(step, context)
            elif step.action_type == "send_notification":
                return await self._execute_send_notification_step(step, context)
            elif step.action_type == "create_ticket":
                return await self._execute_create_ticket_step(step, context)
            elif step.action_type == "update_metrics":
                return await self._execute_update_metrics_step(step, context)
            elif step.action_type == "collect_evidence":
                return await self._execute_collect_evidence_step(step, context)
            else:
                raise ValueError(f"Unknown step action type: {step.action_type}")
                
        except Exception as e:
            logger.error(f"Error executing workflow step {step.name}: {str(e)}")
            raise
    
    async def _execute_generate_report_step(self, step: WorkflowStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute report generation step."""
        try:
            # Get report parameters
            report_format = step.parameters.get('format', 'pdf')
            test_id = context.get('test_id', '')
            
            # Create report data from context
            report_data = context.get('report_data', {})
            if not report_data and test_id:
                # Generate report data from test results
                report_data = await self._generate_report_data_from_test(test_id)
            
            # Generate report
            report_path = await self.report_engine.generate_report(
                PentestReport(**report_data),
                ReportFormat(report_format)
            )
            
            return {
                'report_path': report_path,
                'report_format': report_format,
                'success': True
            }
            
        except Exception as e:
            logger.error(f"Error generating report: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    async def _execute_send_notification_step(self, step: WorkflowStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute notification sending step."""
        try:
            channel = step.parameters.get('channel', 'email')
            template = step.parameters.get('template', 'default')
            
            if channel == 'email':
                return await self._send_email_notification(step, context, template)
            else:
                raise ValueError(f"Unsupported notification channel: {channel}")
                
        except Exception as e:
            logger.error(f"Error sending notification: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    async def _send_email_notification(self, step: WorkflowStep, context: Dict[str, Any], template: str) -> Dict[str, Any]:
        """Send email notification."""
        try:
            # Find email integration
            email_integration = None
            for integration in self.integrations.values():
                if integration.type == IntegrationType.EMAIL_NOTIFICATION and integration.enabled:
                    email_integration = integration
                    break
            
            if not email_integration:
                raise Exception("No email integration configured")
            
            # Parse SMTP settings
            endpoint_parts = email_integration.endpoint.split(':')
            smtp_server = endpoint_parts[0]
            smtp_port = int(endpoint_parts[1]) if len(endpoint_parts) > 1 else 587
            
            # Create email message
            msg = MIMEMultipart()
            msg['From'] = email_integration.settings.get('from_address', 'pentest@example.com')
            msg['Subject'] = self._generate_email_subject(template, context)
            
            # Add recipients
            recipients = step.parameters.get('recipients', 
                                           email_integration.settings.get('recipients', []))
            msg['To'] = ', '.join(recipients)
            
            # Generate email body
            body = self._generate_email_body(template, context)
            msg.attach(MIMEText(body, 'html'))
            
            # Attach report if available
            report_path = context.get('report_path')
            if report_path and Path(report_path).exists():
                with open(report_path, 'rb') as attachment:
                    part = MIMEBase('application', 'octet-stream')
                    part.set_payload(attachment.read())
                    encoders.encode_base64(part)
                    part.add_header(
                        'Content-Disposition',
                        f'attachment; filename= {Path(report_path).name}'
                    )
                    msg.attach(part)
            
            # Send email
            server = smtplib.SMTP(smtp_server, smtp_port)
            if email_integration.settings.get('use_tls', True):
                server.starttls()
            
            if email_integration.credentials.get('username') and email_integration.credentials.get('password'):
                server.login(email_integration.credentials['username'], 
                           email_integration.credentials['password'])
            
            server.send_message(msg)
            server.quit()
            
            return {
                'success': True,
                'recipients': recipients,
                'subject': msg['Subject']
            }
            
        except Exception as e:
            logger.error(f"Error sending email: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _generate_email_subject(self, template: str, context: Dict[str, Any]) -> str:
        """Generate email subject based on template and context."""
        if template == 'test_completion':
            test_name = context.get('test_name', 'Penetration Test')
            return f"Penetration Test Completed: {test_name}"
        elif template == 'finding_discovered':
            severity = context.get('severity', 'Medium')
            return f"New {severity} Severity Finding Discovered"
        else:
            return "Penetration Testing Notification"
    
    def _generate_email_body(self, template: str, context: Dict[str, Any]) -> str:
        """Generate email body based on template and context."""
        if template == 'test_completion':
            return f"""
            <html>
            <body>
                <h2>Penetration Test Completed</h2>
                <p>Test Name: {context.get('test_name', 'N/A')}</p>
                <p>Test ID: {context.get('test_id', 'N/A')}</p>
                <p>Completed At: {context.get('completed_at', datetime.now().isoformat())}</p>
                <p>Total Findings: {context.get('total_findings', 0)}</p>
                
                <h3>Summary by Severity:</h3>
                <ul>
                    <li>Critical: {context.get('critical_findings', 0)}</li>
                    <li>High: {context.get('high_findings', 0)}</li>
                    <li>Medium: {context.get('medium_findings', 0)}</li>
                    <li>Low: {context.get('low_findings', 0)}</li>
                </ul>
                
                <p>Please review the attached report for detailed findings and recommendations.</p>
            </body>
            </html>
            """
        else:
            return "<html><body><p>Penetration testing notification</p></body></html>"
    
    async def _execute_create_ticket_step(self, step: WorkflowStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute ticket creation step."""
        try:
            # Create remediation tasks for findings
            findings = context.get('findings', [])
            created_tasks = []
            
            for finding in findings:
                task = RemediationTask(
                    finding_id=finding.get('id', ''),
                    title=f"Remediate: {finding.get('title', 'Unknown Finding')}",
                    description=finding.get('remediation', ''),
                    priority=self._map_severity_to_priority(finding.get('severity', 'Medium')),
                    assigned_team=step.parameters.get('default_team', 'Security Team'),
                    due_date=datetime.now(timezone.utc) + timedelta(days=30)
                )
                
                await self._store_remediation_task(task)
                created_tasks.append(task.id)
            
            return {
                'success': True,
                'created_tasks': created_tasks,
                'task_count': len(created_tasks)
            }
            
        except Exception as e:
            logger.error(f"Error creating tickets: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _map_severity_to_priority(self, severity: str) -> str:
        """Map vulnerability severity to task priority."""
        severity_priority_map = {
            'Critical': 'Critical',
            'High': 'High',
            'Medium': 'Medium',
            'Low': 'Low',
            'Informational': 'Low'
        }
        return severity_priority_map.get(severity, 'Medium')
    
    async def _execute_update_metrics_step(self, step: WorkflowStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute metrics update step."""
        try:
            # Record metrics based on test results
            test_id = context.get('test_id', '')
            findings = context.get('findings', [])
            
            # Record vulnerability count
            await self.analytics_dashboard.record_metric({
                'metric_type': MetricType.VULNERABILITY_COUNT,
                'value': len(findings),
                'test_id': test_id,
                'timestamp': datetime.now(timezone.utc)
            })
            
            # Record remediation rate if available
            remediation_rate = context.get('remediation_rate', 0.0)
            if remediation_rate > 0:
                await self.analytics_dashboard.record_metric({
                    'metric_type': MetricType.REMEDIATION_RATE,
                    'value': remediation_rate,
                    'test_id': test_id,
                    'timestamp': datetime.now(timezone.utc)
                })
            
            return {
                'success': True,
                'metrics_recorded': 2
            }
            
        except Exception as e:
            logger.error(f"Error updating metrics: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    async def _execute_collect_evidence_step(self, step: WorkflowStep, context: Dict[str, Any]) -> Dict[str, Any]:
        """Execute evidence collection step."""
        try:
            # This would typically be called during testing, not post-test
            # But we can collect additional evidence like final screenshots
            test_id = context.get('test_id', '')
            collected_by = step.parameters.get('collected_by', 'system')
            
            # Collect a final screenshot as evidence
            evidence = await self.evidence_collector.capture_screenshot(
                title="Test Completion Screenshot",
                description="Screenshot captured at test completion",
                test_id=test_id,
                collected_by=collected_by
            )
            
            return {
                'success': True,
                'evidence_id': evidence.id,
                'evidence_type': evidence.type.value
            }
            
        except Exception as e:
            logger.error(f"Error collecting evidence: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    async def _generate_report_data_from_test(self, test_id: str) -> Dict[str, Any]:
        """Generate report data from test results."""
        # This would integrate with the actual test results
        # For now, return sample data structure
        return {
            'id': test_id,
            'title': f"Penetration Test Report - {test_id}",
            'client_name': "Example Organization",
            'test_date': datetime.now(timezone.utc),
            'report_date': datetime.now(timezone.utc),
            'findings': [],
            'executive_summary': {
                'overview': "This penetration test was conducted to assess the security posture.",
                'key_findings': [],
                'recommendations': []
            }
        }
    
    async def _store_workflow_execution(self, execution: WorkflowExecution):
        """Store workflow execution record in database."""
        try:
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR REPLACE INTO workflow_executions (
                    id, workflow_id, status, started_at, completed_at,
                    steps_executed, steps_failed, error_message, results, triggered_by
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                execution.id,
                execution.workflow_id,
                execution.status.value,
                execution.started_at.isoformat(),
                execution.completed_at.isoformat() if execution.completed_at else None,
                json.dumps(execution.steps_executed),
                json.dumps(execution.steps_failed),
                execution.error_message,
                json.dumps(execution.results, default=str),
                execution.triggered_by
            ))
            
            conn.commit()
            conn.close()
            
            logger.debug(f"Workflow execution stored: {execution.id}")
            
        except Exception as e:
            logger.error(f"Error storing workflow execution: {str(e)}")
            raise
    
    async def _store_remediation_task(self, task: RemediationTask):
        """Store remediation task in database."""
        try:
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR REPLACE INTO remediation_tasks (
                    id, finding_id, title, description, priority, assigned_to,
                    assigned_team, status, due_date, created_at, updated_at,
                    estimated_effort, actual_effort, remediation_notes,
                    verification_required, verification_status, external_ticket_id
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                task.id,
                task.finding_id,
                task.title,
                task.description,
                task.priority,
                task.assigned_to,
                task.assigned_team,
                task.status,
                task.due_date.isoformat() if task.due_date else None,
                task.created_at.isoformat(),
                task.updated_at.isoformat(),
                task.estimated_effort,
                task.actual_effort,
                task.remediation_notes,
                task.verification_required,
                task.verification_status,
                task.external_ticket_id
            ))
            
            conn.commit()
            conn.close()
            
            logger.debug(f"Remediation task stored: {task.id}")
            
        except Exception as e:
            logger.error(f"Error storing remediation task: {str(e)}")
            raise
    
    async def trigger_workflow(self, trigger_type: str, context: Dict[str, Any] = None):
        """
        Trigger workflows based on event type.
        
        Args:
            trigger_type: Type of trigger (test_completed, finding_discovered, etc.)
            context: Context data for the workflows
        """
        try:
            triggered_workflows = []
            
            for workflow in self.workflows.values():
                if workflow.enabled and workflow.trigger == trigger_type:
                    execution = await self.execute_workflow(
                        workflow.id,
                        triggered_by=f"trigger:{trigger_type}",
                        context=context
                    )
                    triggered_workflows.append(execution.id)
            
            logger.info(f"Triggered {len(triggered_workflows)} workflows for trigger: {trigger_type}")
            return triggered_workflows
            
        except Exception as e:
            logger.error(f"Error triggering workflows: {str(e)}")
            raise
    
    async def get_remediation_tasks(self, 
                                  status: str = None,
                                  assigned_to: str = None,
                                  priority: str = None) -> List[RemediationTask]:
        """Get remediation tasks with optional filters."""
        try:
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            query = "SELECT * FROM remediation_tasks WHERE 1=1"
            params = []
            
            if status:
                query += " AND status = ?"
                params.append(status)
            
            if assigned_to:
                query += " AND assigned_to = ?"
                params.append(assigned_to)
            
            if priority:
                query += " AND priority = ?"
                params.append(priority)
            
            query += " ORDER BY created_at DESC"
            
            cursor.execute(query, params)
            rows = cursor.fetchall()
            
            tasks = []
            for row in rows:
                task = RemediationTask(
                    id=row[0],
                    finding_id=row[1],
                    title=row[2],
                    description=row[3],
                    priority=row[4],
                    assigned_to=row[5] or "",
                    assigned_team=row[6] or "",
                    status=row[7],
                    due_date=datetime.fromisoformat(row[8]) if row[8] else None,
                    created_at=datetime.fromisoformat(row[9]),
                    updated_at=datetime.fromisoformat(row[10]),
                    estimated_effort=row[11] or "",
                    actual_effort=row[12] or "",
                    remediation_notes=row[13] or "",
                    verification_required=bool(row[14]),
                    verification_status=row[15] or "Pending",
                    external_ticket_id=row[16] or ""
                )
                tasks.append(task)
            
            conn.close()
            return tasks
            
        except Exception as e:
            logger.error(f"Error getting remediation tasks: {str(e)}")
            raise
    
    async def update_remediation_task(self, task_id: str, updates: Dict[str, Any]):
        """Update a remediation task."""
        try:
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            # Build update query
            set_clauses = []
            params = []
            
            for field, value in updates.items():
                if field in ['status', 'assigned_to', 'assigned_team', 'priority', 
                           'estimated_effort', 'actual_effort', 'remediation_notes',
                           'verification_status', 'external_ticket_id']:
                    set_clauses.append(f"{field} = ?")
                    params.append(value)
                elif field == 'due_date' and value:
                    set_clauses.append("due_date = ?")
                    params.append(value.isoformat() if isinstance(value, datetime) else value)
            
            if set_clauses:
                set_clauses.append("updated_at = ?")
                params.append(datetime.now(timezone.utc).isoformat())
                params.append(task_id)
                
                query = f"UPDATE remediation_tasks SET {', '.join(set_clauses)} WHERE id = ?"
                cursor.execute(query, params)
                
                conn.commit()
            
            conn.close()
            
            logger.info(f"Remediation task updated: {task_id}")
            
        except Exception as e:
            logger.error(f"Error updating remediation task: {str(e)}")
            raise

# Convenience functions for external use
async def trigger_test_completion_workflow(test_id: str, 
                                         test_results: Dict[str, Any],
                                         report_format: str = "pdf"):
    """Trigger test completion workflow."""
    integration_layer = PentestIntegrationLayer()
    
    context = {
        'test_id': test_id,
        'test_name': test_results.get('name', f'Test {test_id}'),
        'completed_at': datetime.now(timezone.utc).isoformat(),
        'total_findings': len(test_results.get('findings', [])),
        'findings': test_results.get('findings', []),
        'report_format': report_format
    }
    
    # Calculate findings by severity
    findings = test_results.get('findings', [])
    severity_counts = {'Critical': 0, 'High': 0, 'Medium': 0, 'Low': 0}
    for finding in findings:
        severity = finding.get('severity', 'Medium')
        if severity in severity_counts:
            severity_counts[severity] += 1
    
    context.update({
        'critical_findings': severity_counts['Critical'],
        'high_findings': severity_counts['High'],
        'medium_findings': severity_counts['Medium'],
        'low_findings': severity_counts['Low']
    })
    
    return await integration_layer.trigger_workflow('test_completed', context)

async def create_remediation_tasks_for_findings(findings: List[Dict[str, Any]], 
                                              default_assignee: str = "",
                                              default_team: str = "Security Team"):
    """Create remediation tasks for a list of findings."""
    integration_layer = PentestIntegrationLayer()
    created_tasks = []
    
    for finding in findings:
        task = RemediationTask(
            finding_id=finding.get('id', ''),
            title=f"Remediate: {finding.get('title', 'Unknown Finding')}",
            description=finding.get('remediation', ''),
            priority=integration_layer._map_severity_to_priority(finding.get('severity', 'Medium')),
            assigned_to=default_assignee,
            assigned_team=default_team,
            due_date=datetime.now(timezone.utc) + timedelta(days=30)
        )
        
        await integration_layer._store_remediation_task(task)
        created_tasks.append(task)
    
    return created_tasks

if __name__ == "__main__":
    # Example usage
    async def main():
        integration_layer = PentestIntegrationLayer()
        
        # Example: Trigger test completion workflow
        test_results = {
            'name': 'Web Application Security Test',
            'findings': [
                {
                    'id': 'FINDING-001',
                    'title': 'SQL Injection Vulnerability',
                    'severity': 'High',
                    'remediation': 'Implement parameterized queries'
                },
                {
                    'id': 'FINDING-002', 
                    'title': 'Weak Password Policy',
                    'severity': 'Medium',
                    'remediation': 'Strengthen password requirements'
                }
            ]
        }
        
        workflow_executions = await trigger_test_completion_workflow(
            'TEST-001', 
            test_results
        )
        
        print(f"Triggered {len(workflow_executions)} workflows")
        
        # Get remediation tasks
        tasks = await integration_layer.get_remediation_tasks(status='Open')
        print(f"Open remediation tasks: {len(tasks)}")
    
    asyncio.run(main())