"""
Vulnerability Assessment Framework with Prioritization
====================================================

Enterprise-grade vulnerability assessment and management framework that provides
intelligent vulnerability prioritization, risk-based remediation planning, and
continuous vulnerability monitoring aligned with DoD and NIST standards.

Key Features:
- Advanced vulnerability prioritization using CVSS, EPSS, and SSVC
- Risk-based remediation planning and resource allocation
- Continuous vulnerability monitoring and trend analysis
- Integration with threat intelligence feeds
- Automated vulnerability correlation and deduplication
- SLA-based remediation tracking and reporting
- Business impact assessment and prioritization
- Zero-day vulnerability handling and emergency response

Prioritization Frameworks:
- CVSS 3.1 (Common Vulnerability Scoring System)
- EPSS (Exploit Prediction Scoring System)
- SSVC (Stakeholder-Specific Vulnerability Categorization)
- OWASP Risk Rating Methodology
- Custom DoD/Enterprise Risk Models

Classification: UNCLASSIFIED//FOR OFFICIAL USE ONLY
Version: 1.0 - Vulnerability Assessment Framework
Author: Security Assessment Team
Date: 2025-07-28
"""

import asyncio
import json
import logging
import math
import time
import re
import statistics
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Any, Tuple, Set, Union, NamedTuple
from uuid import UUID, uuid4
from dataclasses import dataclass, field, asdict
from enum import Enum, IntEnum
from collections import defaultdict, deque, Counter
import aiofiles
import aiohttp
import numpy as np
from pathlib import Path
import sqlite3
import hashlib
from urllib.parse import urlparse

# Import security testing infrastructure
from .security_test_engine import (
    SecurityFinding, SecuritySeverity, SecurityTestType
)

# Import existing audit infrastructure
from ..audits.audit_logger import AuditLogger, AuditEvent, AuditEventType, AuditSeverity
from ..audits.enhanced_monitoring_system import EnhancedMonitoringSystem
from ..audits.real_time_alerting import RealTimeAlerting, AlertPriority

logger = logging.getLogger(__name__)


class VulnerabilityPriority(Enum):
    """Vulnerability priority levels for remediation."""
    EMERGENCY = "emergency"      # 0-24 hours
    CRITICAL = "critical"        # 24-72 hours
    HIGH = "high"               # 1-2 weeks
    MEDIUM = "medium"           # 1-3 months
    LOW = "low"                 # 3-6 months
    INFORMATIONAL = "info"      # As resources permit


class RemediationStatus(Enum):
    """Vulnerability remediation status."""
    OPEN = "open"
    ASSIGNED = "assigned"
    IN_PROGRESS = "in_progress"
    TESTING = "testing"
    RESOLVED = "resolved"
    VERIFIED = "verified"
    CLOSED = "closed"
    WONT_FIX = "wont_fix"
    FALSE_POSITIVE = "false_positive"
    RISK_ACCEPTED = "risk_accepted"


class ThreatLevel(Enum):
    """Threat intelligence levels."""
    UNKNOWN = "unknown"
    LOW = "low"
    MODERATE = "moderate"
    HIGH = "high"
    CRITICAL = "critical"
    NATION_STATE = "nation_state"


class AssetCriticality(Enum):
    """Asset criticality levels."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"
    MISSION_CRITICAL = "mission_critical"


# Advanced CVSS 3.1 Scoring System
class AttackVector(Enum):
    """CVSS 3.1 Attack Vector."""
    NETWORK = "N"
    ADJACENT = "A"
    LOCAL = "L"
    PHYSICAL = "P"


class AttackComplexity(Enum):
    """CVSS 3.1 Attack Complexity."""
    LOW = "L"
    HIGH = "H"


class PrivilegesRequired(Enum):
    """CVSS 3.1 Privileges Required."""
    NONE = "N"
    LOW = "L"
    HIGH = "H"


class UserInteraction(Enum):
    """CVSS 3.1 User Interaction."""
    NONE = "N"
    REQUIRED = "R"


class Scope(Enum):
    """CVSS 3.1 Scope."""
    UNCHANGED = "U"
    CHANGED = "C"


class Impact(Enum):
    """CVSS 3.1 Impact."""
    NONE = "N"
    LOW = "L"
    HIGH = "H"


class ModifiedImpact(Enum):
    """CVSS 3.1 Modified Impact for Temporal/Environmental."""
    NOT_DEFINED = "X"
    NONE = "N"
    LOW = "L"
    HIGH = "H"


class ExploitCodeMaturity(Enum):
    """CVSS 3.1 Exploit Code Maturity."""
    NOT_DEFINED = "X"
    UNPROVEN = "U"
    PROOF_OF_CONCEPT = "P"
    FUNCTIONAL = "F"
    HIGH = "H"


class RemediationLevel(Enum):
    """CVSS 3.1 Remediation Level."""
    NOT_DEFINED = "X"
    OFFICIAL_FIX = "O"
    TEMPORARY_FIX = "T"
    WORKAROUND = "W"
    UNAVAILABLE = "U"


class ReportConfidence(Enum):
    """CVSS 3.1 Report Confidence."""
    NOT_DEFINED = "X"
    UNKNOWN = "U"
    REASONABLE = "R"
    CONFIRMED = "C"


class SecurityRequirement(Enum):
    """CVSS 3.1 Security Requirements."""
    NOT_DEFINED = "X"
    LOW = "L"
    MEDIUM = "M"
    HIGH = "H"


class BusinessImpactLevel(IntEnum):
    """Business impact severity levels."""
    MINIMAL = 1
    MINOR = 2
    MODERATE = 3
    SIGNIFICANT = 4
    SEVERE = 5
    CRITICAL = 6
    CATASTROPHIC = 7


class ComplianceFramework(Enum):
    """Compliance frameworks for assessment."""
    NIST_CSF = "nist_csf"
    NIST_800_53 = "nist_800_53" 
    NIST_800_171 = "nist_800_171"
    FedRAMP = "fedramp"
    FISMA = "fisma"
    SOC2 = "soc2"
    ISO_27001 = "iso_27001"
    PCI_DSS = "pci_dss"
    HIPAA = "hipaa"
    DOD_SRG = "dod_srg"
    CJIS = "cjis"


class EPSSLevel(Enum):
    """EPSS threat level categories."""
    VERY_LOW = "very_low"     # 0.0 - 0.1
    LOW = "low"               # 0.1 - 0.3  
    MODERATE = "moderate"     # 0.3 - 0.6
    HIGH = "high"             # 0.6 - 0.8
    VERY_HIGH = "very_high"   # 0.8 - 1.0


@dataclass
class CVSS31BaseMetrics:
    """CVSS 3.1 Base Metrics."""
    attack_vector: AttackVector = AttackVector.NETWORK
    attack_complexity: AttackComplexity = AttackComplexity.LOW
    privileges_required: PrivilegesRequired = PrivilegesRequired.NONE
    user_interaction: UserInteraction = UserInteraction.NONE
    scope: Scope = Scope.UNCHANGED
    confidentiality_impact: Impact = Impact.NONE
    integrity_impact: Impact = Impact.NONE
    availability_impact: Impact = Impact.NONE


@dataclass
class CVSS31TemporalMetrics:
    """CVSS 3.1 Temporal Metrics."""
    exploit_code_maturity: ExploitCodeMaturity = ExploitCodeMaturity.NOT_DEFINED
    remediation_level: RemediationLevel = RemediationLevel.NOT_DEFINED
    report_confidence: ReportConfidence = ReportConfidence.NOT_DEFINED


@dataclass
class CVSS31EnvironmentalMetrics:
    """CVSS 3.1 Environmental Metrics."""
    confidentiality_requirement: SecurityRequirement = SecurityRequirement.NOT_DEFINED
    integrity_requirement: SecurityRequirement = SecurityRequirement.NOT_DEFINED
    availability_requirement: SecurityRequirement = SecurityRequirement.NOT_DEFINED
    modified_attack_vector: AttackVector = AttackVector.NETWORK
    modified_attack_complexity: AttackComplexity = AttackComplexity.LOW
    modified_privileges_required: PrivilegesRequired = PrivilegesRequired.NONE
    modified_user_interaction: UserInteraction = UserInteraction.NONE
    modified_scope: Scope = Scope.UNCHANGED
    modified_confidentiality_impact: ModifiedImpact = ModifiedImpact.NOT_DEFINED
    modified_integrity_impact: ModifiedImpact = ModifiedImpact.NOT_DEFINED
    modified_availability_impact: ModifiedImpact = ModifiedImpact.NOT_DEFINED


@dataclass
class CVSS31Score:
    """Complete CVSS 3.1 scoring."""
    base_metrics: CVSS31BaseMetrics = field(default_factory=CVSS31BaseMetrics)
    temporal_metrics: CVSS31TemporalMetrics = field(default_factory=CVSS31TemporalMetrics)
    environmental_metrics: CVSS31EnvironmentalMetrics = field(default_factory=CVSS31EnvironmentalMetrics)
    
    base_score: float = 0.0
    temporal_score: float = 0.0
    environmental_score: float = 0.0
    
    base_severity: str = "None"
    temporal_severity: str = "None"
    environmental_severity: str = "None"
    
    vector_string: str = ""


@dataclass
class EPSSData:
    """EPSS (Exploit Prediction Scoring System) data."""
    epss_score: float = 0.0
    epss_percentile: float = 0.0
    epss_level: EPSSLevel = EPSSLevel.VERY_LOW
    last_updated: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    data_source: str = "FIRST.org"
    confidence_score: float = 0.0


@dataclass
class BusinessImpactAssessment:
    """Comprehensive business impact assessment."""
    financial_impact: float = 0.0  # Estimated dollar impact
    operational_impact: BusinessImpactLevel = BusinessImpactLevel.MINIMAL
    reputational_impact: BusinessImpactLevel = BusinessImpactLevel.MINIMAL
    regulatory_impact: BusinessImpactLevel = BusinessImpactLevel.MINIMAL
    
    # Service impact
    service_degradation_risk: float = 0.0  # 0-1 scale
    availability_impact_hours: float = 0.0
    affected_users: int = 0
    
    # Data impact
    data_breach_risk: float = 0.0  # 0-1 scale
    sensitive_data_exposed: bool = False
    records_at_risk: int = 0
    
    # Compliance impact
    compliance_violations: List[ComplianceFramework] = field(default_factory=list)
    regulatory_penalties: float = 0.0
    
    # Strategic impact
    competitive_advantage_loss: BusinessImpactLevel = BusinessImpactLevel.MINIMAL
    intellectual_property_risk: BusinessImpactLevel = BusinessImpactLevel.MINIMAL
    
    assessment_confidence: float = 0.5  # 0-1 scale
    assessment_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc))


@dataclass
class RemediationSLA:
    """Detailed SLA tracking for remediation."""
    priority: VulnerabilityPriority = VulnerabilityPriority.MEDIUM
    target_hours: int = 2160  # 90 days default
    escalation_hours: int = 2304  # 96 days (escalation point)
    breach_hours: int = 2400  # 100 days (SLA breach)
    
    created_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    due_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc) + timedelta(days=90))
    escalation_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc) + timedelta(days=96))
    breach_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc) + timedelta(days=100))
    
    is_escalated: bool = False
    is_breached: bool = False
    escalation_reason: str = ""
    
    notification_sent: bool = False
    escalation_notification_sent: bool = False
    breach_notification_sent: bool = False


@dataclass
class VulnerabilityContext:
    """Enhanced vulnerability context for prioritization."""
    # Asset information
    asset_id: str = ""
    asset_name: str = ""
    asset_criticality: AssetCriticality = AssetCriticality.MEDIUM
    asset_classification: str = "UNCLASSIFIED"
    asset_owner: str = ""
    
    # Network context
    network_exposure: str = "internal"  # internal, dmz, external
    network_reachability: List[str] = field(default_factory=list)
    
    # Business context
    business_function: str = ""
    business_impact_score: float = 5.0  # 1-10 scale
    regulatory_requirements: List[str] = field(default_factory=list)
    
    # Technical context
    operating_system: str = ""
    application_stack: List[str] = field(default_factory=list)
    data_sensitivity: str = "medium"
    
    # Temporal context
    discovery_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    last_scan_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    patch_availability_date: Optional[datetime] = None
    
    # Threat intelligence
    active_exploitation: bool = False
    exploit_available: bool = False
    exploit_complexity: str = "high"  # low, medium, high
    threat_actor_interest: ThreatLevel = ThreatLevel.UNKNOWN


@dataclass
class VulnerabilityAssessment:
    """Comprehensive vulnerability assessment result."""
    vulnerability_id: str = field(default_factory=lambda: str(uuid4()))
    assessment_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    
    # Source vulnerability
    source_finding: SecurityFinding = field(default_factory=SecurityFinding)
    
    # Advanced scoring systems
    cvss31_score: CVSS31Score = field(default_factory=CVSS31Score)
    epss_data: EPSSData = field(default_factory=EPSSData)
    business_impact: BusinessImpactAssessment = field(default_factory=BusinessImpactAssessment)
    
    # Legacy compatibility
    cvss_v3_score: float = 0.0
    cvss_v3_vector: str = ""
    epss_score: float = 0.0  # Exploit Prediction Scoring System
    ssvc_decision: str = ""  # Stakeholder-Specific Vulnerability Categorization
    
    # Custom scoring
    enterprise_risk_score: float = 0.0
    dod_risk_score: float = 0.0
    composite_priority_score: float = 0.0
    
    # Prioritization
    priority_level: VulnerabilityPriority = VulnerabilityPriority.MEDIUM
    sla_tracking: RemediationSLA = field(default_factory=RemediationSLA)
    
    # Legacy SLA fields for compatibility
    remediation_sla_hours: int = 2160  # 90 days default
    due_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc) + timedelta(days=90))
    
    # Context
    vulnerability_context: VulnerabilityContext = field(default_factory=VulnerabilityContext)
    
    # Remediation
    remediation_status: RemediationStatus = RemediationStatus.OPEN
    assigned_to: Optional[str] = None
    remediation_effort_hours: float = 0.0
    remediation_complexity: str = "medium"
    remediation_cost: float = 0.0
    
    # Advanced remediation tracking
    remediation_team: Optional[str] = None
    remediation_tools_required: List[str] = field(default_factory=list)
    testing_requirements: List[str] = field(default_factory=list)
    rollback_plan_required: bool = False
    
    # Tracking
    first_seen: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    last_seen: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    recurrence_count: int = 1
    
    # Verification
    verification_required: bool = True
    verification_method: str = ""
    verified_fixed: bool = False
    verification_date: Optional[datetime] = None
    
    # Advanced verification
    automated_verification_possible: bool = False
    verification_scripts: List[str] = field(default_factory=list)
    post_remediation_testing: List[str] = field(default_factory=list)
    
    # Reporting
    false_positive_likelihood: float = 0.0
    suppressed: bool = False
    suppression_reason: str = ""
    
    # Advanced reporting
    executive_summary: str = ""
    technical_details: str = ""
    risk_acceptance_justification: str = ""
    
    # Compliance
    compliance_violations: List[str] = field(default_factory=list)
    regulatory_impact: str = "medium"
    compliance_frameworks: List[ComplianceFramework] = field(default_factory=list)
    
    # Advanced compliance
    control_mappings: Dict[str, List[str]] = field(default_factory=dict)
    audit_trail: List[Dict[str, Any]] = field(default_factory=list)
    
    # Metrics
    time_to_detect_hours: float = 0.0
    time_to_remediate_hours: float = 0.0
    age_days: float = 0.0
    
    # Advanced metrics
    mean_time_to_acknowledge: float = 0.0
    mean_time_to_assign: float = 0.0
    mean_time_to_fix: float = 0.0
    mean_time_to_verify: float = 0.0
    
    # Cost analysis
    detection_cost: float = 0.0
    analysis_cost: float = 0.0
    total_cost_of_ownership: float = 0.0


@dataclass
class RemediationPlan:
    """Comprehensive remediation plan."""
    plan_id: str = field(default_factory=lambda: str(uuid4()))
    creation_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    
    # Plan details
    plan_name: str = ""
    description: str = ""
    priority: VulnerabilityPriority = VulnerabilityPriority.MEDIUM
    
    # Scope
    vulnerability_assessments: List[VulnerabilityAssessment] = field(default_factory=list)
    affected_assets: List[str] = field(default_factory=list)
    business_functions_impacted: List[str] = field(default_factory=list)
    
    # Resources
    estimated_effort_hours: float = 0.0
    estimated_cost: float = 0.0
    required_skills: List[str] = field(default_factory=list)
    resource_allocation: Dict[str, float] = field(default_factory=dict)
    
    # Timeline
    planned_start_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    planned_completion_date: datetime = field(default_factory=lambda: datetime.now(timezone.utc) + timedelta(days=30))
    actual_start_date: Optional[datetime] = None
    actual_completion_date: Optional[datetime] = None
    
    # Dependencies
    prerequisites: List[str] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)
    
    # Approval
    approval_required: bool = True
    approver: Optional[str] = None
    approval_date: Optional[datetime] = None
    approved: bool = False
    
    # Execution
    execution_status: str = "planned"
    progress_percentage: float = 0.0
    milestones: List[Dict[str, Any]] = field(default_factory=list)
    
    # Verification
    verification_plan: str = ""
    success_criteria: List[str] = field(default_factory=list)
    verification_completed: bool = False
    
    # Risk management
    implementation_risks: List[str] = field(default_factory=list)
    rollback_plan: str = ""
    business_impact_assessment: str = ""


class CVSS31Calculator:
    """
    Advanced CVSS 3.1 calculator implementing the official FIRST.org specification.
    
    This class provides accurate CVSS 3.1 base, temporal, and environmental 
    score calculations with proper vector string generation.
    """
    
    # CVSS 3.1 scoring constants from FIRST.org specification
    IMPACT_WEIGHTS = {
        Impact.NONE: 0.0,
        Impact.LOW: 0.22,
        Impact.HIGH: 0.56
    }
    
    EXPLOITABILITY_WEIGHTS = {
        AttackVector.NETWORK: 0.85,
        AttackVector.ADJACENT: 0.62,
        AttackVector.LOCAL: 0.55,
        AttackVector.PHYSICAL: 0.2,
        
        AttackComplexity.LOW: 0.77,
        AttackComplexity.HIGH: 0.44,
        
        UserInteraction.NONE: 0.85,
        UserInteraction.REQUIRED: 0.62
    }
    
    PRIVILEGES_REQUIRED_WEIGHTS = {
        (PrivilegesRequired.NONE, Scope.UNCHANGED): 0.85,
        (PrivilegesRequired.NONE, Scope.CHANGED): 0.85,
        (PrivilegesRequired.LOW, Scope.UNCHANGED): 0.62,
        (PrivilegesRequired.LOW, Scope.CHANGED): 0.68,
        (PrivilegesRequired.HIGH, Scope.UNCHANGED): 0.27,
        (PrivilegesRequired.HIGH, Scope.CHANGED): 0.5
    }
    
    TEMPORAL_WEIGHTS = {
        ExploitCodeMaturity.NOT_DEFINED: 1.0,
        ExploitCodeMaturity.UNPROVEN: 0.91,
        ExploitCodeMaturity.PROOF_OF_CONCEPT: 0.94,
        ExploitCodeMaturity.FUNCTIONAL: 0.97,
        ExploitCodeMaturity.HIGH: 1.0,
        
        RemediationLevel.NOT_DEFINED: 1.0,
        RemediationLevel.OFFICIAL_FIX: 0.95,
        RemediationLevel.TEMPORARY_FIX: 0.96,
        RemediationLevel.WORKAROUND: 0.97,
        RemediationLevel.UNAVAILABLE: 1.0,
        
        ReportConfidence.NOT_DEFINED: 1.0,
        ReportConfidence.UNKNOWN: 0.92,
        ReportConfidence.REASONABLE: 0.96,
        ReportConfidence.CONFIRMED: 1.0
    }
    
    ENVIRONMENTAL_WEIGHTS = {
        SecurityRequirement.NOT_DEFINED: 1.0,
        SecurityRequirement.LOW: 0.5,
        SecurityRequirement.MEDIUM: 1.0,
        SecurityRequirement.HIGH: 1.5
    }
    
    def calculate_cvss31_score(self, cvss_score: CVSS31Score) -> CVSS31Score:
        """Calculate complete CVSS 3.1 score with all metrics."""
        # Calculate base score
        cvss_score.base_score = self._calculate_base_score(cvss_score.base_metrics)
        cvss_score.base_severity = self._get_severity_rating(cvss_score.base_score)
        
        # Calculate temporal score
        cvss_score.temporal_score = self._calculate_temporal_score(
            cvss_score.base_score, cvss_score.temporal_metrics
        )
        cvss_score.temporal_severity = self._get_severity_rating(cvss_score.temporal_score)
        
        # Calculate environmental score
        cvss_score.environmental_score = self._calculate_environmental_score(
            cvss_score.base_metrics, cvss_score.temporal_metrics, 
            cvss_score.environmental_metrics
        )
        cvss_score.environmental_severity = self._get_severity_rating(cvss_score.environmental_score)
        
        # Generate vector string
        cvss_score.vector_string = self._generate_vector_string(
            cvss_score.base_metrics, cvss_score.temporal_metrics, 
            cvss_score.environmental_metrics
        )
        
        return cvss_score
    
    def _calculate_base_score(self, base_metrics: CVSS31BaseMetrics) -> float:
        """Calculate CVSS 3.1 base score."""
        # Calculate impact sub-score
        isc_base = (
            1 - (
                (1 - self.IMPACT_WEIGHTS[base_metrics.confidentiality_impact]) *
                (1 - self.IMPACT_WEIGHTS[base_metrics.integrity_impact]) *
                (1 - self.IMPACT_WEIGHTS[base_metrics.availability_impact])
            )
        )
        
        if base_metrics.scope == Scope.UNCHANGED:
            impact = 6.42 * isc_base
        else:  # Scope.CHANGED
            impact = 7.52 * (isc_base - 0.029) - 3.25 * pow(isc_base - 0.02, 15)
        
        # Calculate exploitability sub-score
        exploitability = (
            8.22 * 
            self.EXPLOITABILITY_WEIGHTS[base_metrics.attack_vector] *
            self.EXPLOITABILITY_WEIGHTS[base_metrics.attack_complexity] *
            self.PRIVILEGES_REQUIRED_WEIGHTS[(base_metrics.privileges_required, base_metrics.scope)] *
            self.EXPLOITABILITY_WEIGHTS[base_metrics.user_interaction]
        )
        
        # Calculate base score
        if impact <= 0:
            return 0.0
        
        if base_metrics.scope == Scope.UNCHANGED:
            base_score = min(10.0, impact + exploitability)
        else:  # Scope.CHANGED
            base_score = min(10.0, 1.08 * (impact + exploitability))
        
        return math.ceil(base_score * 10) / 10
    
    def _calculate_temporal_score(self, base_score: float, temporal_metrics: CVSS31TemporalMetrics) -> float:
        """Calculate CVSS 3.1 temporal score."""
        temporal_score = (
            base_score *
            self.TEMPORAL_WEIGHTS[temporal_metrics.exploit_code_maturity] *
            self.TEMPORAL_WEIGHTS[temporal_metrics.remediation_level] *
            self.TEMPORAL_WEIGHTS[temporal_metrics.report_confidence]
        )
        
        return math.ceil(temporal_score * 10) / 10
    
    def _calculate_environmental_score(
        self, 
        base_metrics: CVSS31BaseMetrics,
        temporal_metrics: CVSS31TemporalMetrics,
        env_metrics: CVSS31EnvironmentalMetrics
    ) -> float:
        """Calculate CVSS 3.1 environmental score."""
        # Use modified metrics if defined, otherwise use base metrics
        modified_c_impact = (env_metrics.modified_confidentiality_impact 
                           if env_metrics.modified_confidentiality_impact != ModifiedImpact.NOT_DEFINED
                           else Impact(base_metrics.confidentiality_impact.value))
        
        modified_i_impact = (env_metrics.modified_integrity_impact
                           if env_metrics.modified_integrity_impact != ModifiedImpact.NOT_DEFINED
                           else Impact(base_metrics.integrity_impact.value))
        
        modified_a_impact = (env_metrics.modified_availability_impact
                           if env_metrics.modified_availability_impact != ModifiedImpact.NOT_DEFINED
                           else Impact(base_metrics.availability_impact.value))
        
        # Calculate modified impact
        isc_modified = min(
            1 - (
                (1 - self.IMPACT_WEIGHTS[modified_c_impact] * self.ENVIRONMENTAL_WEIGHTS[env_metrics.confidentiality_requirement]) *
                (1 - self.IMPACT_WEIGHTS[modified_i_impact] * self.ENVIRONMENTAL_WEIGHTS[env_metrics.integrity_requirement]) *
                (1 - self.IMPACT_WEIGHTS[modified_a_impact] * self.ENVIRONMENTAL_WEIGHTS[env_metrics.availability_requirement])
            ),
            0.915
        )
        
        if base_metrics.scope == Scope.UNCHANGED:
            modified_impact = 6.42 * isc_modified
        else:  # Scope.CHANGED
            modified_impact = 7.52 * (isc_modified - 0.029) - 3.25 * pow(isc_modified - 0.02, 15)
        
        # Calculate modified exploitability (using base metrics if modified not defined)
        av = (env_metrics.modified_attack_vector 
              if hasattr(env_metrics, 'modified_attack_vector') 
              else base_metrics.attack_vector)
        
        ac = (env_metrics.modified_attack_complexity
              if hasattr(env_metrics, 'modified_attack_complexity')
              else base_metrics.attack_complexity)
        
        pr = (env_metrics.modified_privileges_required
              if hasattr(env_metrics, 'modified_privileges_required')
              else base_metrics.privileges_required)
        
        ui = (env_metrics.modified_user_interaction
              if hasattr(env_metrics, 'modified_user_interaction')
              else base_metrics.user_interaction)
        
        scope = (env_metrics.modified_scope
                if hasattr(env_metrics, 'modified_scope')
                else base_metrics.scope)
        
        modified_exploitability = (
            8.22 *
            self.EXPLOITABILITY_WEIGHTS[av] *
            self.EXPLOITABILITY_WEIGHTS[ac] *
            self.PRIVILEGES_REQUIRED_WEIGHTS[(pr, scope)] *
            self.EXPLOITABILITY_WEIGHTS[ui]
        )
        
        # Calculate environmental score
        if modified_impact <= 0:
            return 0.0
        
        if scope == Scope.UNCHANGED:
            env_score = min(10.0, modified_impact + modified_exploitability)
        else:  # Scope.CHANGED
            env_score = min(10.0, 1.08 * (modified_impact + modified_exploitability))
        
        # Apply temporal multipliers
        env_score *= (
            self.TEMPORAL_WEIGHTS[temporal_metrics.exploit_code_maturity] *
            self.TEMPORAL_WEIGHTS[temporal_metrics.remediation_level] *
            self.TEMPORAL_WEIGHTS[temporal_metrics.report_confidence]
        )
        
        return math.ceil(env_score * 10) / 10
    
    def _get_severity_rating(self, score: float) -> str:
        """Get severity rating from CVSS score."""
        if score == 0.0:
            return "None"
        elif score <= 3.9:
            return "Low"
        elif score <= 6.9:
            return "Medium"
        elif score <= 8.9:
            return "High"
        else:
            return "Critical"
    
    def _generate_vector_string(
        self,
        base_metrics: CVSS31BaseMetrics,
        temporal_metrics: CVSS31TemporalMetrics,
        env_metrics: CVSS31EnvironmentalMetrics
    ) -> str:
        """Generate CVSS 3.1 vector string."""
        vector = f"CVSS:3.1/AV:{base_metrics.attack_vector.value}"
        vector += f"/AC:{base_metrics.attack_complexity.value}"
        vector += f"/PR:{base_metrics.privileges_required.value}"
        vector += f"/UI:{base_metrics.user_interaction.value}"
        vector += f"/S:{base_metrics.scope.value}"
        vector += f"/C:{base_metrics.confidentiality_impact.value}"
        vector += f"/I:{base_metrics.integrity_impact.value}"
        vector += f"/A:{base_metrics.availability_impact.value}"
        
        # Add temporal metrics if not default
        if temporal_metrics.exploit_code_maturity != ExploitCodeMaturity.NOT_DEFINED:
            vector += f"/E:{temporal_metrics.exploit_code_maturity.value}"
        if temporal_metrics.remediation_level != RemediationLevel.NOT_DEFINED:
            vector += f"/RL:{temporal_metrics.remediation_level.value}"
        if temporal_metrics.report_confidence != ReportConfidence.NOT_DEFINED:
            vector += f"/RC:{temporal_metrics.report_confidence.value}"
        
        # Add environmental metrics if not default
        if env_metrics.confidentiality_requirement != SecurityRequirement.NOT_DEFINED:
            vector += f"/CR:{env_metrics.confidentiality_requirement.value}"
        if env_metrics.integrity_requirement != SecurityRequirement.NOT_DEFINED:
            vector += f"/IR:{env_metrics.integrity_requirement.value}"
        if env_metrics.availability_requirement != SecurityRequirement.NOT_DEFINED:
            vector += f"/AR:{env_metrics.availability_requirement.value}"
        
        return vector
    
    def parse_vector_string(self, vector_string: str) -> CVSS31Score:
        """Parse CVSS 3.1 vector string into score object."""
        if not vector_string.startswith("CVSS:3.1/"):
            raise ValueError("Invalid CVSS 3.1 vector string")
        
        cvss_score = CVSS31Score()
        
        # Parse components
        components = vector_string.replace("CVSS:3.1/", "").split("/")
        metrics_dict = {}
        
        for component in components:
            if ":" in component:
                key, value = component.split(":", 1)
                metrics_dict[key] = value
        
        # Parse base metrics (required)
        cvss_score.base_metrics.attack_vector = AttackVector(metrics_dict["AV"])
        cvss_score.base_metrics.attack_complexity = AttackComplexity(metrics_dict["AC"])
        cvss_score.base_metrics.privileges_required = PrivilegesRequired(metrics_dict["PR"])
        cvss_score.base_metrics.user_interaction = UserInteraction(metrics_dict["UI"])
        cvss_score.base_metrics.scope = Scope(metrics_dict["S"])
        cvss_score.base_metrics.confidentiality_impact = Impact(metrics_dict["C"])
        cvss_score.base_metrics.integrity_impact = Impact(metrics_dict["I"])
        cvss_score.base_metrics.availability_impact = Impact(metrics_dict["A"])
        
        # Parse temporal metrics (optional)
        if "E" in metrics_dict:
            cvss_score.temporal_metrics.exploit_code_maturity = ExploitCodeMaturity(metrics_dict["E"])
        if "RL" in metrics_dict:
            cvss_score.temporal_metrics.remediation_level = RemediationLevel(metrics_dict["RL"])
        if "RC" in metrics_dict:
            cvss_score.temporal_metrics.report_confidence = ReportConfidence(metrics_dict["RC"])
        
        # Parse environmental metrics (optional)
        if "CR" in metrics_dict:
            cvss_score.environmental_metrics.confidentiality_requirement = SecurityRequirement(metrics_dict["CR"])
        if "IR" in metrics_dict:
            cvss_score.environmental_metrics.integrity_requirement = SecurityRequirement(metrics_dict["IR"])
        if "AR" in metrics_dict:
            cvss_score.environmental_metrics.availability_requirement = SecurityRequirement(metrics_dict["AR"])
        
        # Calculate scores
        return self.calculate_cvss31_score(cvss_score)


class EPSSIntegration:
    """
    EPSS (Exploit Prediction Scoring System) integration for real-time 
    exploit probability assessment.
    """
    
    def __init__(self):
        self.epss_api_url = "https://api.first.org/data/v1/epss"
        self.cache_duration_hours = 24
        self.epss_cache = {}
        
    async def get_epss_score(self, cve_id: str) -> EPSSData:
        """Get EPSS score for a specific CVE."""
        # Check cache first
        cache_key = f"epss_{cve_id}"
        if cache_key in self.epss_cache:
            cached_data = self.epss_cache[cache_key]
            if (datetime.now(timezone.utc) - cached_data.last_updated).hours < self.cache_duration_hours:
                return cached_data
        
        try:
            async with aiohttp.ClientSession() as session:
                params = {"cve": cve_id}
                async with session.get(self.epss_api_url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        return self._parse_epss_response(data, cve_id)
                    else:
                        logger.warning(f"EPSS API returned status {response.status} for CVE {cve_id}")
                        return self._generate_fallback_epss(cve_id)
        
        except Exception as e:
            logger.error(f"Failed to fetch EPSS data for {cve_id}: {e}")
            return self._generate_fallback_epss(cve_id)
    
    def _parse_epss_response(self, data: Dict[str, Any], cve_id: str) -> EPSSData:
        """Parse EPSS API response."""
        if "data" in data and len(data["data"]) > 0:
            epss_entry = data["data"][0]
            epss_score = float(epss_entry.get("epss", 0.0))
            epss_percentile = float(epss_entry.get("percentile", 0.0))
            
            epss_data = EPSSData(
                epss_score=epss_score,
                epss_percentile=epss_percentile,
                epss_level=self._categorize_epss_score(epss_score),
                last_updated=datetime.now(timezone.utc),
                data_source="FIRST.org",
                confidence_score=0.9  # High confidence for official EPSS data
            )
            
            # Cache the result
            self.epss_cache[f"epss_{cve_id}"] = epss_data
            return epss_data
        
        return self._generate_fallback_epss(cve_id)
    
    def _generate_fallback_epss(self, cve_id: str) -> EPSSData:
        """Generate fallback EPSS score when API is unavailable."""
        # Basic heuristic based on CVE ID patterns
        fallback_score = 0.1  # Default low probability
        
        return EPSSData(
            epss_score=fallback_score,
            epss_percentile=10.0,
            epss_level=self._categorize_epss_score(fallback_score),
            last_updated=datetime.now(timezone.utc),
            data_source="Fallback heuristic",
            confidence_score=0.3  # Low confidence for fallback
        )
    
    def _categorize_epss_score(self, score: float) -> EPSSLevel:
        """Categorize EPSS score into threat levels."""
        if score >= 0.8:
            return EPSSLevel.VERY_HIGH
        elif score >= 0.6:
            return EPSSLevel.HIGH
        elif score >= 0.3:
            return EPSSLevel.MODERATE
        elif score >= 0.1:
            return EPSSLevel.LOW
        else:
            return EPSSLevel.VERY_LOW


class BusinessImpactCalculator:
    """
    Advanced business impact calculator that assesses financial, operational,
    and strategic impacts of vulnerabilities.
    """
    
    def __init__(self):
        # Default impact multipliers (can be customized per organization)
        self.sector_multipliers = {
            "financial": 2.5,
            "healthcare": 2.2,
            "government": 2.0,
            "defense": 3.0,
            "technology": 1.8,
            "retail": 1.5,
            "manufacturing": 1.3,
            "education": 1.2
        }
        
        # Cost factors per record for data breaches
        self.data_breach_costs = {
            "pii": 150.0,  # Cost per PII record
            "phi": 250.0,  # Cost per PHI record
            "financial": 200.0,  # Cost per financial record
            "classified": 500.0,  # Cost per classified record
            "ip": 1000.0  # Cost per IP record
        }
    
    async def calculate_business_impact(
        self,
        assessment: VulnerabilityAssessment,
        sector: str = "technology",
        annual_revenue: float = 100_000_000,  # $100M default
        custom_factors: Optional[Dict[str, float]] = None
    ) -> BusinessImpactAssessment:
        """Calculate comprehensive business impact assessment."""
        
        impact = BusinessImpactAssessment()
        context = assessment.vulnerability_context
        
        # Calculate financial impact
        impact.financial_impact = await self._calculate_financial_impact(
            assessment, sector, annual_revenue, custom_factors
        )
        
        # Assess operational impact
        impact.operational_impact = self._assess_operational_impact(assessment)
        
        # Assess reputational impact
        impact.reputational_impact = self._assess_reputational_impact(assessment)
        
        # Assess regulatory impact
        impact.regulatory_impact = self._assess_regulatory_impact(assessment)
        
        # Calculate service impact metrics
        impact.service_degradation_risk = self._calculate_service_risk(assessment)
        impact.availability_impact_hours = self._estimate_availability_impact(assessment)
        impact.affected_users = self._estimate_affected_users(assessment)
        
        # Calculate data impact metrics
        impact.data_breach_risk = self._calculate_data_breach_risk(assessment)
        impact.sensitive_data_exposed = self._assess_data_exposure_risk(assessment)
        impact.records_at_risk = self._estimate_records_at_risk(assessment)
        
        # Assess compliance impact
        impact.compliance_violations = self._identify_compliance_violations(assessment)
        impact.regulatory_penalties = self._estimate_regulatory_penalties(assessment, sector)
        
        # Assess strategic impact
        impact.competitive_advantage_loss = self._assess_competitive_impact(assessment)
        impact.intellectual_property_risk = self._assess_ip_risk(assessment)
        
        # Set confidence and metadata
        impact.assessment_confidence = self._calculate_confidence_score(assessment)
        impact.assessment_date = datetime.now(timezone.utc)
        
        return impact
    
    async def _calculate_financial_impact(
        self,
        assessment: VulnerabilityAssessment,
        sector: str,
        annual_revenue: float,
        custom_factors: Optional[Dict[str, float]]
    ) -> float:
        """Calculate estimated financial impact."""
        base_impact = 0.0
        
        # Factor in vulnerability severity
        cvss_score = assessment.cvss31_score.base_score or assessment.cvss_v3_score
        severity_multiplier = {
            0.0: 0.0,
            3.9: 0.001,  # Low
            6.9: 0.005,  # Medium  
            8.9: 0.02,   # High
            10.0: 0.05   # Critical
        }
        
        # Find appropriate multiplier
        for threshold, multiplier in sorted(severity_multiplier.items()):
            if cvss_score <= threshold:
                base_impact = annual_revenue * multiplier
                break
        
        # Apply sector-specific multiplier
        sector_mult = self.sector_multipliers.get(sector, 1.0)
        base_impact *= sector_mult
        
        # Factor in asset criticality
        criticality_mult = {
            AssetCriticality.LOW: 0.5,
            AssetCriticality.MEDIUM: 1.0,
            AssetCriticality.HIGH: 2.0,
            AssetCriticality.CRITICAL: 3.0,
            AssetCriticality.MISSION_CRITICAL: 5.0
        }.get(assessment.vulnerability_context.asset_criticality, 1.0)
        
        base_impact *= criticality_mult
        
        # Factor in data sensitivity
        if assessment.business_impact.sensitive_data_exposed:
            data_breach_cost = self._calculate_data_breach_cost(assessment)
            base_impact += data_breach_cost
        
        # Apply custom factors
        if custom_factors:
            for factor, value in custom_factors.items():
                base_impact *= value
        
        return base_impact
    
    def _calculate_data_breach_cost(self, assessment: VulnerabilityAssessment) -> float:
        """Calculate estimated data breach cost."""
        # Estimate records at risk
        records = self._estimate_records_at_risk(assessment)
        
        # Determine data type and cost per record
        data_sensitivity = assessment.vulnerability_context.data_sensitivity
        cost_per_record = self.data_breach_costs.get(data_sensitivity, 100.0)
        
        # Factor in breach probability
        breach_probability = assessment.business_impact.data_breach_risk
        
        return records * cost_per_record * breach_probability
    
    def _assess_operational_impact(self, assessment: VulnerabilityAssessment) -> BusinessImpactLevel:
        """Assess operational impact level."""
        cvss_score = assessment.cvss31_score.base_score or assessment.cvss_v3_score
        availability_impact = assessment.cvss31_score.base_metrics.availability_impact
        
        if availability_impact == Impact.HIGH and cvss_score >= 7.0:
            return BusinessImpactLevel.SEVERE
        elif availability_impact == Impact.HIGH or cvss_score >= 6.0:
            return BusinessImpactLevel.SIGNIFICANT
        elif availability_impact == Impact.LOW or cvss_score >= 4.0:
            return BusinessImpactLevel.MODERATE
        else:
            return BusinessImpactLevel.MINOR
    
    def _assess_reputational_impact(self, assessment: VulnerabilityAssessment) -> BusinessImpactLevel:
        """Assess reputational impact level."""
        if assessment.vulnerability_context.network_exposure == "external":
            if assessment.business_impact.sensitive_data_exposed:
                return BusinessImpactLevel.SEVERE
            elif assessment.cvss31_score.base_score >= 7.0:
                return BusinessImpactLevel.SIGNIFICANT
            else:
                return BusinessImpactLevel.MODERATE
        else:
            return BusinessImpactLevel.MINOR
    
    def _assess_regulatory_impact(self, assessment: VulnerabilityAssessment) -> BusinessImpactLevel:
        """Assess regulatory impact level."""
        if assessment.compliance_frameworks:
            critical_frameworks = [ComplianceFramework.HIPAA, ComplianceFramework.PCI_DSS, 
                                 ComplianceFramework.FedRAMP, ComplianceFramework.DOD_SRG]
            
            if any(fw in critical_frameworks for fw in assessment.compliance_frameworks):
                return BusinessImpactLevel.CRITICAL
            else:
                return BusinessImpactLevel.SIGNIFICANT
        
        return BusinessImpactLevel.MINOR
    
    def _calculate_service_risk(self, assessment: VulnerabilityAssessment) -> float:
        """Calculate service degradation risk (0-1 scale)."""
        availability_impact = assessment.cvss31_score.base_metrics.availability_impact
        
        if availability_impact == Impact.HIGH:
            return 0.8
        elif availability_impact == Impact.LOW:
            return 0.3
        else:
            return 0.1
    
    def _estimate_availability_impact(self, assessment: VulnerabilityAssessment) -> float:
        """Estimate availability impact in hours."""
        availability_impact = assessment.cvss31_score.base_metrics.availability_impact
        asset_criticality = assessment.vulnerability_context.asset_criticality
        
        base_hours = {
            Impact.HIGH: 24.0,
            Impact.LOW: 4.0,
            Impact.NONE: 0.0
        }.get(availability_impact, 0.0)
        
        criticality_mult = {
            AssetCriticality.MISSION_CRITICAL: 3.0,
            AssetCriticality.CRITICAL: 2.0,
            AssetCriticality.HIGH: 1.5,
            AssetCriticality.MEDIUM: 1.0,
            AssetCriticality.LOW: 0.5
        }.get(asset_criticality, 1.0)
        
        return base_hours * criticality_mult
    
    def _estimate_affected_users(self, assessment: VulnerabilityAssessment) -> int:
        """Estimate number of affected users."""
        # This would typically query actual system data
        # For now, we'll use heuristics based on asset criticality
        
        base_users = {
            AssetCriticality.MISSION_CRITICAL: 100000,
            AssetCriticality.CRITICAL: 50000,
            AssetCriticality.HIGH: 10000,
            AssetCriticality.MEDIUM: 1000,
            AssetCriticality.LOW: 100
        }.get(assessment.vulnerability_context.asset_criticality, 100)
        
        # Factor in network exposure
        exposure_mult = {
            "external": 3.0,
            "dmz": 1.5,
            "internal": 1.0
        }.get(assessment.vulnerability_context.network_exposure, 1.0)
        
        return int(base_users * exposure_mult)
    
    def _calculate_data_breach_risk(self, assessment: VulnerabilityAssessment) -> float:
        """Calculate data breach risk (0-1 scale)."""
        confidentiality_impact = assessment.cvss31_score.base_metrics.confidentiality_impact
        
        if confidentiality_impact == Impact.HIGH:
            return 0.9
        elif confidentiality_impact == Impact.LOW:
            return 0.4
        else:
            return 0.1
    
    def _assess_data_exposure_risk(self, assessment: VulnerabilityAssessment) -> bool:
        """Assess if sensitive data is at risk of exposure."""
        confidentiality_impact = assessment.cvss31_score.base_metrics.confidentiality_impact
        data_sensitivity = assessment.vulnerability_context.data_sensitivity
        
        return (confidentiality_impact != Impact.NONE and 
                data_sensitivity in ["high", "critical"])
    
    def _estimate_records_at_risk(self, assessment: VulnerabilityAssessment) -> int:
        """Estimate number of records at risk."""
        # Heuristic based on asset criticality and data sensitivity
        base_records = {
            AssetCriticality.MISSION_CRITICAL: 1000000,
            AssetCriticality.CRITICAL: 500000,
            AssetCriticality.HIGH: 100000,
            AssetCriticality.MEDIUM: 10000,
            AssetCriticality.LOW: 1000
        }.get(assessment.vulnerability_context.asset_criticality, 1000)
        
        sensitivity_mult = {
            "critical": 2.0,
            "high": 1.5,
            "medium": 1.0,
            "low": 0.5
        }.get(assessment.vulnerability_context.data_sensitivity, 1.0)
        
        return int(base_records * sensitivity_mult)
    
    def _identify_compliance_violations(self, assessment: VulnerabilityAssessment) -> List[ComplianceFramework]:
        """Identify potential compliance violations."""
        violations = []
        
        # Map vulnerability types to compliance frameworks
        vuln_type = assessment.source_finding.vulnerability_type
        
        if vuln_type in ["sql_injection", "xss", "hardcoded_secrets"]:
            violations.extend([ComplianceFramework.PCI_DSS, ComplianceFramework.SOC2])
        
        if assessment.vulnerability_context.data_sensitivity in ["high", "critical"]:
            violations.extend([ComplianceFramework.NIST_800_53, ComplianceFramework.ISO_27001])
        
        if assessment.vulnerability_context.asset_classification != "UNCLASSIFIED":
            violations.extend([ComplianceFramework.DOD_SRG, ComplianceFramework.FISMA])
        
        return list(set(violations))  # Remove duplicates
    
    def _estimate_regulatory_penalties(self, assessment: VulnerabilityAssessment, sector: str) -> float:
        """Estimate potential regulatory penalties."""
        if not assessment.business_impact.compliance_violations:
            return 0.0
        
        # Base penalty amounts by framework
        penalty_amounts = {
            ComplianceFramework.PCI_DSS: 100000.0,
            ComplianceFramework.HIPAA: 1000000.0,
            ComplianceFramework.SOC2: 50000.0,
            ComplianceFramework.ISO_27001: 25000.0,
            ComplianceFramework.DOD_SRG: 500000.0,
            ComplianceFramework.FISMA: 250000.0
        }
        
        total_penalty = 0.0
        for framework in assessment.business_impact.compliance_violations:
            penalty = penalty_amounts.get(framework, 10000.0)
            
            # Factor in breach probability
            if assessment.business_impact.data_breach_risk > 0.5:
                penalty *= 2.0
            
            total_penalty += penalty
        
        return total_penalty
    
    def _assess_competitive_impact(self, assessment: VulnerabilityAssessment) -> BusinessImpactLevel:
        """Assess competitive advantage loss."""
        if assessment.vulnerability_context.data_sensitivity == "critical":
            return BusinessImpactLevel.SIGNIFICANT
        elif assessment.vulnerability_context.asset_criticality == AssetCriticality.MISSION_CRITICAL:
            return BusinessImpactLevel.MODERATE
        else:
            return BusinessImpactLevel.MINIMAL
    
    def _assess_ip_risk(self, assessment: VulnerabilityAssessment) -> BusinessImpactLevel:
        """Assess intellectual property risk."""
        confidentiality_impact = assessment.cvss31_score.base_metrics.confidentiality_impact
        
        if (confidentiality_impact == Impact.HIGH and 
            assessment.vulnerability_context.data_sensitivity == "critical"):
            return BusinessImpactLevel.CRITICAL
        elif confidentiality_impact == Impact.HIGH:
            return BusinessImpactLevel.SIGNIFICANT
        elif confidentiality_impact == Impact.LOW:
            return BusinessImpactLevel.MODERATE
        else:
            return BusinessImpactLevel.MINIMAL
    
    def _calculate_confidence_score(self, assessment: VulnerabilityAssessment) -> float:
        """Calculate confidence score for business impact assessment."""
        confidence = 0.5  # Base confidence
        
        # Higher confidence for well-known vulnerability types
        known_vulns = ["sql_injection", "xss", "command_injection"]
        if assessment.source_finding.vulnerability_type in known_vulns:
            confidence += 0.2
        
        # Higher confidence for CVSS scored vulnerabilities
        if assessment.cvss31_score.base_score > 0:
            confidence += 0.2
        
        # Higher confidence for assets with known characteristics
        if assessment.vulnerability_context.asset_criticality != AssetCriticality.MEDIUM:
            confidence += 0.1
        
        return min(1.0, confidence)


class VulnerabilityAssessmentFramework:
    """
    Comprehensive vulnerability assessment framework with intelligent
    prioritization and risk-based remediation planning.
    """
    
    def __init__(
        self,
        audit_logger: AuditLogger,
        monitoring_system: EnhancedMonitoringSystem,
        real_time_alerting: RealTimeAlerting
    ):
        """Initialize vulnerability assessment framework."""
        # Core components
        self.audit_logger = audit_logger
        self.monitoring_system = monitoring_system
        self.real_time_alerting = real_time_alerting
        
        # Advanced scoring components
        self.cvss_calculator = CVSS31Calculator()
        self.epss_integration = EPSSIntegration()
        self.business_impact_calculator = BusinessImpactCalculator()
        
        # Assessment storage
        self.vulnerability_assessments: Dict[str, VulnerabilityAssessment] = {}
        self.remediation_plans: Dict[str, RemediationPlan] = {}
        
        # Configuration
        self.scoring_weights = {
            "cvss": 0.4,
            "epss": 0.2,
            "asset_criticality": 0.15,
            "business_impact": 0.1,
            "threat_intelligence": 0.1,
            "network_exposure": 0.05
        }
        
        # SLA definitions (hours)
        self.sla_hours = {
            VulnerabilityPriority.EMERGENCY: 24,
            VulnerabilityPriority.CRITICAL: 72,
            VulnerabilityPriority.HIGH: 336,      # 2 weeks
            VulnerabilityPriority.MEDIUM: 2160,   # 90 days
            VulnerabilityPriority.LOW: 4320,      # 180 days
            VulnerabilityPriority.INFORMATIONAL: 8760  # 1 year
        }
        
        # Threat intelligence sources
        self.threat_intel_sources = [
            "NVD",  # National Vulnerability Database
            "CVE",  # Common Vulnerabilities and Exposures
            "CISA", # Cybersecurity and Infrastructure Security Agency
            "US-CERT",
            "MITRE",
            "Commercial Feeds"
        ]
        
        # Database for persistence
        self.db_path = "vulnerability_assessments.db"
        self._init_database()
        
        # Metrics
        self.metrics = {
            "total_assessments": 0,
            "emergency_vulnerabilities": 0,
            "critical_vulnerabilities": 0,
            "sla_breaches": 0,
            "average_time_to_remediate": 0.0,
            "remediation_rate": 0.0,
            "false_positive_rate": 0.0
        }
        
        logger.info("Vulnerability Assessment Framework initialized")
    
    def _init_database(self):
        """Initialize SQLite database for vulnerability tracking."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS vulnerability_assessments (
                vulnerability_id TEXT PRIMARY KEY,
                assessment_date TEXT,
                source_finding_data TEXT,
                cvss_score REAL,
                epss_score REAL,
                enterprise_risk_score REAL,
                priority_level TEXT,
                remediation_status TEXT,
                assigned_to TEXT,
                due_date TEXT,
                context_data TEXT,
                created_date TEXT,
                updated_date TEXT
            )
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS remediation_plans (
                plan_id TEXT PRIMARY KEY,
                plan_name TEXT,
                priority TEXT,
                estimated_effort_hours REAL,
                estimated_cost REAL,
                planned_start_date TEXT,
                planned_completion_date TEXT,
                execution_status TEXT,
                progress_percentage REAL,
                created_date TEXT,
                updated_date TEXT
            )
        """)
        
        conn.commit()
        conn.close()
    
    async def assess_vulnerability(
        self,
        security_finding: SecurityFinding,
        context: Optional[VulnerabilityContext] = None
    ) -> VulnerabilityAssessment:
        """Perform comprehensive vulnerability assessment."""
        if context is None:
            context = VulnerabilityContext()
        
        # Create assessment
        assessment = VulnerabilityAssessment(
            source_finding=security_finding,
            vulnerability_context=context
        )
        
        # Calculate advanced CVSS 3.1 score
        await self._calculate_advanced_cvss_score(assessment)
        
        # Get EPSS data
        await self._fetch_epss_data(assessment)
        
        # Calculate business impact assessment
        await self._calculate_business_impact_assessment(assessment)
        
        # Calculate legacy scores for compatibility
        await self._calculate_cvss_score(assessment)
        await self._calculate_epss_score(assessment)
        await self._calculate_enterprise_risk_score(assessment)
        await self._calculate_dod_risk_score(assessment)
        
        # Determine composite priority
        await self._calculate_composite_priority(assessment)
        
        # Set priority level and advanced SLA tracking
        self._determine_priority_level(assessment)
        await self._configure_advanced_sla_tracking(assessment)
        
        # Enhance with threat intelligence
        await self._enrich_with_threat_intelligence(assessment)
        
        # Store assessment
        self.vulnerability_assessments[assessment.vulnerability_id] = assessment
        await self._persist_assessment(assessment)
        
        # Log assessment
        await self._log_assessment_event(assessment)
        
        # Send alerts for high-priority vulnerabilities
        if assessment.priority_level in [VulnerabilityPriority.EMERGENCY, VulnerabilityPriority.CRITICAL]:
            await self._send_priority_alert(assessment)
        
        # Update metrics
        self._update_assessment_metrics(assessment)
        
        logger.info(f"Vulnerability assessment completed: {assessment.vulnerability_id} (Priority: {assessment.priority_level.value})")
        
        return assessment
    
    async def _calculate_advanced_cvss_score(self, assessment: VulnerabilityAssessment):
        """Calculate advanced CVSS 3.1 score with full metrics."""
        finding = assessment.source_finding
        
        # If we already have a CVSS vector, parse it
        if finding.cvss_vector and finding.cvss_vector.startswith("CVSS:3.1/"):
            try:
                assessment.cvss31_score = self.cvss_calculator.parse_vector_string(finding.cvss_vector)
                return
            except Exception as e:
                logger.warning(f"Failed to parse CVSS vector {finding.cvss_vector}: {e}")
        
        # Map vulnerability types to CVSS 3.1 base metrics
        cvss_score = CVSS31Score()
        
        vuln_mappings = {
            "sql_injection": {
                "attack_vector": AttackVector.NETWORK,
                "attack_complexity": AttackComplexity.LOW,
                "privileges_required": PrivilegesRequired.NONE,
                "user_interaction": UserInteraction.NONE,
                "scope": Scope.UNCHANGED,
                "confidentiality_impact": Impact.HIGH,
                "integrity_impact": Impact.HIGH,
                "availability_impact": Impact.NONE
            },
            "xss": {
                "attack_vector": AttackVector.NETWORK,
                "attack_complexity": AttackComplexity.LOW,
                "privileges_required": PrivilegesRequired.NONE,
                "user_interaction": UserInteraction.REQUIRED,
                "scope": Scope.CHANGED,
                "confidentiality_impact": Impact.LOW,
                "integrity_impact": Impact.LOW,
                "availability_impact": Impact.NONE
            },
            "command_injection": {
                "attack_vector": AttackVector.NETWORK,
                "attack_complexity": AttackComplexity.LOW,
                "privileges_required": PrivilegesRequired.NONE,
                "user_interaction": UserInteraction.NONE,
                "scope": Scope.UNCHANGED,
                "confidentiality_impact": Impact.HIGH,
                "integrity_impact": Impact.HIGH,
                "availability_impact": Impact.HIGH
            },
            "path_traversal": {
                "attack_vector": AttackVector.NETWORK,
                "attack_complexity": AttackComplexity.LOW,
                "privileges_required": PrivilegesRequired.NONE,
                "user_interaction": UserInteraction.NONE,
                "scope": Scope.UNCHANGED,
                "confidentiality_impact": Impact.HIGH,
                "integrity_impact": Impact.NONE,
                "availability_impact": Impact.NONE
            },
            "hardcoded_secrets": {
                "attack_vector": AttackVector.LOCAL,
                "attack_complexity": AttackComplexity.LOW,
                "privileges_required": PrivilegesRequired.LOW,
                "user_interaction": UserInteraction.NONE,
                "scope": Scope.UNCHANGED,
                "confidentiality_impact": Impact.HIGH,
                "integrity_impact": Impact.NONE,
                "availability_impact": Impact.NONE
            },
            "weak_crypto": {
                "attack_vector": AttackVector.NETWORK,
                "attack_complexity": AttackComplexity.HIGH,
                "privileges_required": PrivilegesRequired.NONE,
                "user_interaction": UserInteraction.NONE,
                "scope": Scope.UNCHANGED,
                "confidentiality_impact": Impact.HIGH,
                "integrity_impact": Impact.NONE,
                "availability_impact": Impact.NONE
            }
        }
        
        vuln_type = finding.vulnerability_type
        if vuln_type in vuln_mappings:
            mapping = vuln_mappings[vuln_type]
            
            # Set base metrics
            for attr, value in mapping.items():
                setattr(cvss_score.base_metrics, attr, value)
        else:
            # Default mapping based on severity
            severity_mappings = {
                SecuritySeverity.CRITICAL: (Impact.HIGH, Impact.HIGH, Impact.HIGH),
                SecuritySeverity.HIGH: (Impact.HIGH, Impact.LOW, Impact.NONE),
                SecuritySeverity.MEDIUM: (Impact.LOW, Impact.LOW, Impact.NONE),
                SecuritySeverity.LOW: (Impact.LOW, Impact.NONE, Impact.NONE),
                SecuritySeverity.INFO: (Impact.NONE, Impact.NONE, Impact.NONE)
            }
            
            if finding.severity in severity_mappings:
                c_impact, i_impact, a_impact = severity_mappings[finding.severity]
                cvss_score.base_metrics.confidentiality_impact = c_impact
                cvss_score.base_metrics.integrity_impact = i_impact
                cvss_score.base_metrics.availability_impact = a_impact
        
        # Set temporal metrics based on context
        context = assessment.vulnerability_context
        if context.exploit_available:
            if context.exploit_complexity == "low":
                cvss_score.temporal_metrics.exploit_code_maturity = ExploitCodeMaturity.FUNCTIONAL
            else:
                cvss_score.temporal_metrics.exploit_code_maturity = ExploitCodeMaturity.PROOF_OF_CONCEPT
        
        if context.patch_availability_date:
            days_since_patch = (datetime.now(timezone.utc) - context.patch_availability_date).days
            if days_since_patch < 30:
                cvss_score.temporal_metrics.remediation_level = RemediationLevel.OFFICIAL_FIX
            elif days_since_patch < 90:
                cvss_score.temporal_metrics.remediation_level = RemediationLevel.TEMPORARY_FIX
        
        # Set environmental metrics based on asset context
        if context.asset_criticality == AssetCriticality.MISSION_CRITICAL:
            cvss_score.environmental_metrics.confidentiality_requirement = SecurityRequirement.HIGH
            cvss_score.environmental_metrics.integrity_requirement = SecurityRequirement.HIGH
            cvss_score.environmental_metrics.availability_requirement = SecurityRequirement.HIGH
        elif context.asset_criticality in [AssetCriticality.CRITICAL, AssetCriticality.HIGH]:
            cvss_score.environmental_metrics.confidentiality_requirement = SecurityRequirement.MEDIUM
            cvss_score.environmental_metrics.integrity_requirement = SecurityRequirement.MEDIUM
            cvss_score.environmental_metrics.availability_requirement = SecurityRequirement.MEDIUM
        
        # Calculate scores
        assessment.cvss31_score = self.cvss_calculator.calculate_cvss31_score(cvss_score)
        
        # Update legacy fields for compatibility
        assessment.cvss_v3_score = assessment.cvss31_score.base_score
        assessment.cvss_v3_vector = assessment.cvss31_score.vector_string
    
    async def _fetch_epss_data(self, assessment: VulnerabilityAssessment):
        """Fetch EPSS data for the vulnerability."""
        finding = assessment.source_finding
        
        if finding.cve_id:
            try:
                epss_data = await self.epss_integration.get_epss_score(finding.cve_id)
                assessment.epss_data = epss_data
                
                # Update legacy field for compatibility
                assessment.epss_score = epss_data.epss_score
                
            except Exception as e:
                logger.error(f"Failed to fetch EPSS data for {finding.cve_id}: {e}")
                # Use fallback EPSS calculation
                await self._calculate_epss_score(assessment)
                assessment.epss_data.epss_score = assessment.epss_score
        else:
            # Use fallback EPSS calculation for non-CVE vulnerabilities
            await self._calculate_epss_score(assessment)
            assessment.epss_data.epss_score = assessment.epss_score
            assessment.epss_data.epss_level = self.epss_integration._categorize_epss_score(assessment.epss_score)
    
    async def _calculate_business_impact_assessment(self, assessment: VulnerabilityAssessment):
        """Calculate comprehensive business impact assessment."""
        try:
            # Determine organization sector and revenue (would come from config in production)
            sector = "technology"  # Default - could be configurable
            annual_revenue = 100_000_000  # $100M default - could be configurable
            
            # Calculate business impact
            assessment.business_impact = await self.business_impact_calculator.calculate_business_impact(
                assessment, sector, annual_revenue
            )
            
            # Update compliance frameworks based on business impact assessment
            assessment.compliance_frameworks.extend(assessment.business_impact.compliance_violations)
            assessment.compliance_frameworks = list(set(assessment.compliance_frameworks))  # Remove duplicates
            
        except Exception as e:
            logger.error(f"Failed to calculate business impact assessment: {e}")
            # Use default business impact
            assessment.business_impact = BusinessImpactAssessment()
    
    async def _configure_advanced_sla_tracking(self, assessment: VulnerabilityAssessment):
        """Configure advanced SLA tracking."""
        priority = assessment.priority_level
        
        # Configure SLA based on priority
        sla = RemediationSLA(priority=priority)
        
        # Set target hours based on priority
        target_hours = self.sla_hours.get(priority, 2160)
        sla.target_hours = target_hours
        sla.escalation_hours = int(target_hours * 1.1)  # 10% buffer before escalation
        sla.breach_hours = int(target_hours * 1.2)  # 20% buffer before breach
        
        # Set dates
        now = datetime.now(timezone.utc)
        sla.due_date = now + timedelta(hours=target_hours)
        sla.escalation_date = now + timedelta(hours=sla.escalation_hours)
        sla.breach_date = now + timedelta(hours=sla.breach_hours)
        
        # Special handling for emergency and critical vulnerabilities
        if priority == VulnerabilityPriority.EMERGENCY:
            sla.escalation_hours = 12  # Escalate after 12 hours
            sla.breach_hours = 36      # Breach after 36 hours
            sla.escalation_date = now + timedelta(hours=12)
            sla.breach_date = now + timedelta(hours=36)
        elif priority == VulnerabilityPriority.CRITICAL:
            sla.escalation_hours = 48  # Escalate after 48 hours
            sla.breach_hours = 96      # Breach after 96 hours
            sla.escalation_date = now + timedelta(hours=48)
            sla.breach_date = now + timedelta(hours=96)
        
        assessment.sla_tracking = sla
        
        # Update legacy fields for compatibility
        assessment.remediation_sla_hours = target_hours
        assessment.due_date = sla.due_date
    
    async def _calculate_cvss_score(self, assessment: VulnerabilityAssessment):
        """Calculate CVSS v3.1 score."""
        finding = assessment.source_finding
        
        # If CVSS score already provided, use it
        if finding.cvss_score > 0:
            assessment.cvss_v3_score = finding.cvss_score
            assessment.cvss_v3_vector = finding.cvss_vector
            return
        
        # Calculate CVSS based on vulnerability type
        cvss_mappings = {
            "sql_injection": {"base": 8.5, "vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:N"},
            "xss": {"base": 6.1, "vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N"},
            "command_injection": {"base": 9.8, "vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"},
            "path_traversal": {"base": 7.5, "vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N"},
            "hardcoded_secrets": {"base": 7.5, "vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N"},
            "weak_crypto": {"base": 5.9, "vector": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:N/A:N"},
            "insecure_random": {"base": 5.3, "vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N"},
            "vulnerable_dependency": {"base": 7.3, "vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:L"}
        }
        
        vuln_type = finding.vulnerability_type
        if vuln_type in cvss_mappings:
            mapping = cvss_mappings[vuln_type]
            assessment.cvss_v3_score = mapping["base"]
            assessment.cvss_v3_vector = mapping["vector"]
        else:
            # Default scoring based on severity
            severity_scores = {
                SecuritySeverity.CRITICAL: 9.0,
                SecuritySeverity.HIGH: 7.0,
                SecuritySeverity.MEDIUM: 4.0,
                SecuritySeverity.LOW: 2.0,
                SecuritySeverity.INFO: 0.0
            }
            assessment.cvss_v3_score = severity_scores.get(finding.severity, 0.0)
            assessment.cvss_v3_vector = "CVSS:3.1/AV:?/AC:?/PR:?/UI:?/S:?/C:?/I:?/A:?"
    
    async def _calculate_epss_score(self, assessment: VulnerabilityAssessment):
        """Calculate Exploit Prediction Scoring System (EPSS) score."""
        # EPSS score predicts the probability of exploitation
        # In production, this would query the actual EPSS API
        
        finding = assessment.source_finding
        context = assessment.vulnerability_context
        
        # Base probability based on vulnerability type
        base_probability = {
            "command_injection": 0.8,
            "sql_injection": 0.6,
            "xss": 0.4,
            "path_traversal": 0.5,
            "hardcoded_secrets": 0.7,
            "weak_crypto": 0.2,
            "insecure_random": 0.1,
            "vulnerable_dependency": 0.3
        }
        
        base_prob = base_probability.get(finding.vulnerability_type, 0.1)
        
        # Adjust based on context
        if context.network_exposure == "external":
            base_prob *= 1.5
        elif context.network_exposure == "dmz":
            base_prob *= 1.2
        
        if context.active_exploitation:
            base_prob = min(0.95, base_prob * 2.0)
        
        if context.exploit_available:
            base_prob = min(0.9, base_prob * 1.5)
        
        # Adjust based on complexity
        if context.exploit_complexity == "low":
            base_prob *= 1.3
        elif context.exploit_complexity == "high":
            base_prob *= 0.7
        
        assessment.epss_score = min(1.0, base_prob)
    
    async def _calculate_enterprise_risk_score(self, assessment: VulnerabilityAssessment):
        """Calculate enterprise-specific risk score."""
        context = assessment.vulnerability_context
        
        # Base score from CVSS
        base_score = assessment.cvss_v3_score
        
        # Asset criticality multiplier
        criticality_multiplier = {
            AssetCriticality.LOW: 0.5,
            AssetCriticality.MEDIUM: 1.0,
            AssetCriticality.HIGH: 1.5,
            AssetCriticality.CRITICAL: 2.0,
            AssetCriticality.MISSION_CRITICAL: 2.5
        }
        
        multiplier = criticality_multiplier.get(context.asset_criticality, 1.0)
        
        # Business impact adjustment
        business_impact_adjustment = (context.business_impact_score / 10.0) * 2.0
        
        # Network exposure adjustment
        exposure_adjustment = {
            "internal": 0.0,
            "dmz": 1.0,
            "external": 2.0
        }.get(context.network_exposure, 0.0)
        
        # Data sensitivity adjustment
        sensitivity_adjustment = {
            "low": 0.0,
            "medium": 0.5,
            "high": 1.0,
            "critical": 1.5
        }.get(context.data_sensitivity, 0.5)
        
        # Calculate final score
        enterprise_score = (
            base_score * multiplier +
            business_impact_adjustment +
            exposure_adjustment +
            sensitivity_adjustment
        )
        
        assessment.enterprise_risk_score = min(10.0, enterprise_score)
    
    async def _calculate_dod_risk_score(self, assessment: VulnerabilityAssessment):
        """Calculate DoD-specific risk score."""
        context = assessment.vulnerability_context
        
        # DoD uses stricter scoring
        base_score = assessment.cvss_v3_score
        
        # Classification level impact
        classification_impact = {
            "UNCLASSIFIED": 1.0,
            "CUI": 1.2,
            "CONFIDENTIAL": 1.5,
            "SECRET": 2.0,
            "TOP SECRET": 2.5
        }.get(context.asset_classification, 1.0)
        
        # Mission criticality
        mission_impact = {
            AssetCriticality.LOW: 1.0,
            AssetCriticality.MEDIUM: 1.2,
            AssetCriticality.HIGH: 1.5,
            AssetCriticality.CRITICAL: 2.0,
            AssetCriticality.MISSION_CRITICAL: 3.0
        }.get(context.asset_criticality, 1.0)
        
        # Threat actor consideration
        threat_multiplier = {
            ThreatLevel.UNKNOWN: 1.0,
            ThreatLevel.LOW: 1.0,
            ThreatLevel.MODERATE: 1.2,
            ThreatLevel.HIGH: 1.5,
            ThreatLevel.CRITICAL: 2.0,
            ThreatLevel.NATION_STATE: 2.5
        }.get(context.threat_actor_interest, 1.0)
        
        # DoD specific adjustments
        dod_score = base_score * classification_impact * mission_impact * threat_multiplier
        
        # Additional DoD considerations
        if context.active_exploitation:
            dod_score *= 1.5
        
        if context.network_exposure == "external":
            dod_score *= 1.3
        
        assessment.dod_risk_score = min(10.0, dod_score)
    
    async def _calculate_composite_priority(self, assessment: VulnerabilityAssessment):
        """Calculate composite priority score using weighted algorithm."""
        weights = self.scoring_weights
        context = assessment.vulnerability_context
        
        # Normalize scores to 0-10 scale
        cvss_normalized = assessment.cvss_v3_score
        epss_normalized = assessment.epss_score * 10
        
        asset_criticality_score = {
            AssetCriticality.LOW: 2,
            AssetCriticality.MEDIUM: 4,
            AssetCriticality.HIGH: 6,
            AssetCriticality.CRITICAL: 8,
            AssetCriticality.MISSION_CRITICAL: 10
        }.get(context.asset_criticality, 4)
        
        business_impact_normalized = context.business_impact_score
        
        threat_intel_score = 0
        if context.active_exploitation:
            threat_intel_score += 5
        if context.exploit_available:
            threat_intel_score += 3
        if context.threat_actor_interest != ThreatLevel.UNKNOWN:
            threat_intel_score += 2
        threat_intel_score = min(10, threat_intel_score)
        
        network_exposure_score = {
            "internal": 2,
            "dmz": 6,
            "external": 10
        }.get(context.network_exposure, 2)
        
        # Calculate weighted composite score
        composite_score = (
            cvss_normalized * weights["cvss"] +
            epss_normalized * weights["epss"] +
            asset_criticality_score * weights["asset_criticality"] +
            business_impact_normalized * weights["business_impact"] +
            threat_intel_score * weights["threat_intelligence"] +
            network_exposure_score * weights["network_exposure"]
        )
        
        assessment.composite_priority_score = composite_score
    
    def _determine_priority_level(self, assessment: VulnerabilityAssessment):
        """Determine vulnerability priority level."""
        composite_score = assessment.composite_priority_score
        context = assessment.vulnerability_context
        
        # Emergency conditions
        if (context.active_exploitation or 
            assessment.cvss_v3_score >= 9.0 or
            (context.asset_criticality == AssetCriticality.MISSION_CRITICAL and assessment.cvss_v3_score >= 7.0)):
            assessment.priority_level = VulnerabilityPriority.EMERGENCY
        
        # Critical conditions
        elif (composite_score >= 8.0 or
              assessment.cvss_v3_score >= 7.0 or
              (context.exploit_available and assessment.cvss_v3_score >= 5.0)):
            assessment.priority_level = VulnerabilityPriority.CRITICAL
        
        # High conditions
        elif composite_score >= 6.0 or assessment.cvss_v3_score >= 4.0:
            assessment.priority_level = VulnerabilityPriority.HIGH
        
        # Medium conditions
        elif composite_score >= 3.0 or assessment.cvss_v3_score >= 1.0:
            assessment.priority_level = VulnerabilityPriority.MEDIUM
        
        # Low conditions
        elif composite_score >= 1.0:
            assessment.priority_level = VulnerabilityPriority.LOW
        
        # Informational
        else:
            assessment.priority_level = VulnerabilityPriority.INFORMATIONAL
    
    def _set_remediation_sla(self, assessment: VulnerabilityAssessment):
        """Set remediation SLA based on priority."""
        sla_hours = self.sla_hours.get(assessment.priority_level, 2160)
        assessment.remediation_sla_hours = sla_hours
        assessment.due_date = assessment.assessment_date + timedelta(hours=sla_hours)
    
    async def _enrich_with_threat_intelligence(self, assessment: VulnerabilityAssessment):
        """Enrich assessment with threat intelligence data."""
        finding = assessment.source_finding
        
        # In production, this would query real threat intelligence feeds
        # Simulated threat intelligence enrichment
        
        if finding.cve_id:
            # Check for active exploitation
            if finding.cve_id in ["CVE-2023-44487", "CVE-2023-46604"]:  # Example active CVEs
                assessment.vulnerability_context.active_exploitation = True
                assessment.vulnerability_context.threat_actor_interest = ThreatLevel.HIGH
        
        # Check vulnerability type for exploit availability
        high_exploit_types = ["sql_injection", "command_injection", "path_traversal"]
        if finding.vulnerability_type in high_exploit_types:
            assessment.vulnerability_context.exploit_available = True
            assessment.vulnerability_context.exploit_complexity = "low"
    
    async def create_remediation_plan(
        self,
        vulnerability_ids: List[str],
        plan_name: str = "",
        priority: Optional[VulnerabilityPriority] = None
    ) -> RemediationPlan:
        """Create comprehensive remediation plan."""
        assessments = [self.vulnerability_assessments[vid] for vid in vulnerability_ids 
                      if vid in self.vulnerability_assessments]
        
        if not assessments:
            raise ValueError("No valid vulnerability assessments found")
        
        # Determine plan priority
        if priority is None:
            highest_priority = min([a.priority_level for a in assessments], 
                                 key=lambda x: list(VulnerabilityPriority).index(x))
            priority = highest_priority
        
        # Create plan
        plan = RemediationPlan(
            plan_name=plan_name or f"Remediation Plan {datetime.now().strftime('%Y%m%d_%H%M')}",
            priority=priority,
            vulnerability_assessments=assessments
        )
        
        # Calculate effort and resources
        await self._calculate_remediation_effort(plan)
        
        # Set timeline
        self._set_remediation_timeline(plan)
        
        # Identify dependencies
        await self._identify_remediation_dependencies(plan)
        
        # Store plan
        self.remediation_plans[plan.plan_id] = plan
        await self._persist_remediation_plan(plan)
        
        # Log plan creation
        await self._log_remediation_plan_event("PLAN_CREATED", plan)
        
        logger.info(f"Remediation plan created: {plan.plan_id} with {len(assessments)} vulnerabilities")
        
        return plan
    
    async def _calculate_remediation_effort(self, plan: RemediationPlan):
        """Calculate estimated remediation effort."""
        total_effort = 0.0
        total_cost = 0.0
        
        effort_by_type = {
            "sql_injection": 8.0,      # hours
            "xss": 4.0,
            "command_injection": 12.0,
            "path_traversal": 6.0,
            "hardcoded_secrets": 2.0,
            "weak_crypto": 16.0,
            "insecure_random": 4.0,
            "vulnerable_dependency": 1.0,
            "configuration_issue": 2.0,
            "missing_security_headers": 1.0
        }
        
        for assessment in plan.vulnerability_assessments:
            vuln_type = assessment.source_finding.vulnerability_type
            base_effort = effort_by_type.get(vuln_type, 4.0)
            
            # Adjust based on complexity and asset criticality
            complexity_multiplier = {
                "low": 0.5,
                "medium": 1.0,
                "high": 2.0
            }.get(assessment.remediation_complexity, 1.0)
            
            criticality_multiplier = {
                AssetCriticality.LOW: 0.8,
                AssetCriticality.MEDIUM: 1.0,
                AssetCriticality.HIGH: 1.2,
                AssetCriticality.CRITICAL: 1.5,
                AssetCriticality.MISSION_CRITICAL: 2.0
            }.get(assessment.vulnerability_context.asset_criticality, 1.0)
            
            effort = base_effort * complexity_multiplier * criticality_multiplier
            cost = effort * 150  # $150/hour estimate
            
            assessment.remediation_effort_hours = effort
            assessment.remediation_cost = cost
            
            total_effort += effort
            total_cost += cost
        
        plan.estimated_effort_hours = total_effort
        plan.estimated_cost = total_cost
    
    def _set_remediation_timeline(self, plan: RemediationPlan):
        """Set remediation timeline based on priority and effort."""
        # Calculate planned completion based on priority SLA
        earliest_due = min([a.due_date for a in plan.vulnerability_assessments])
        
        # Buffer time for planning and testing
        buffer_hours = plan.estimated_effort_hours * 0.3  # 30% buffer
        
        plan.planned_completion_date = min(
            earliest_due,
            plan.planned_start_date + timedelta(hours=plan.estimated_effort_hours + buffer_hours)
        )
    
    async def _identify_remediation_dependencies(self, plan: RemediationPlan):
        """Identify remediation dependencies and prerequisites."""
        dependencies = []
        prerequisites = []
        
        # Check for common dependencies
        vuln_types = [a.source_finding.vulnerability_type for a in plan.vulnerability_assessments]
        
        if "weak_crypto" in vuln_types:
            prerequisites.append("Cryptography library upgrade approval")
            dependencies.append("Security team review")
        
        if "vulnerable_dependency" in vuln_types:
            prerequisites.append("Dependency compatibility testing")
            dependencies.append("QA regression testing")
        
        if any("injection" in vt for vt in vuln_types):
            prerequisites.append("Code review and testing environment")
            dependencies.append("Application security testing")
        
        plan.prerequisites = prerequisites
        plan.dependencies = dependencies
    
    async def check_sla_compliance(self) -> Dict[str, Any]:
        """Check SLA compliance across all active vulnerabilities."""
        now = datetime.now(timezone.utc)
        compliance_data = {
            "total_vulnerabilities": 0,
            "on_time": 0,
            "approaching_escalation": 0,
            "escalated": 0,
            "breached": 0,
            "escalation_details": [],
            "breach_details": []
        }
        
        for assessment in self.vulnerability_assessments.values():
            if assessment.remediation_status in [RemediationStatus.OPEN, RemediationStatus.ASSIGNED, RemediationStatus.IN_PROGRESS]:
                compliance_data["total_vulnerabilities"] += 1
                sla = assessment.sla_tracking
                
                if now > sla.breach_date:
                    compliance_data["breached"] += 1
                    if not sla.breach_notification_sent:
                        compliance_data["breach_details"].append({
                            "vulnerability_id": assessment.vulnerability_id,
                            "priority": assessment.priority_level.value,
                            "breach_date": sla.breach_date.isoformat(),
                            "days_overdue": (now - sla.breach_date).days
                        })
                        # Mark as notified to prevent spam
                        sla.is_breached = True
                        sla.breach_notification_sent = True
                
                elif now > sla.escalation_date:
                    compliance_data["escalated"] += 1
                    if not sla.escalation_notification_sent:
                        compliance_data["escalation_details"].append({
                            "vulnerability_id": assessment.vulnerability_id,
                            "priority": assessment.priority_level.value,
                            "escalation_date": sla.escalation_date.isoformat(),
                            "hours_since_escalation": (now - sla.escalation_date).total_seconds() / 3600
                        })
                        # Mark as escalated to prevent spam
                        sla.is_escalated = True
                        sla.escalation_notification_sent = True
                
                elif (sla.escalation_date - now).total_seconds() / 3600 <= 24:  # Within 24 hours of escalation
                    compliance_data["approaching_escalation"] += 1
                
                else:
                    compliance_data["on_time"] += 1
        
        # Calculate compliance percentage
        total = compliance_data["total_vulnerabilities"]
        if total > 0:
            compliance_data["sla_compliance_percentage"] = (compliance_data["on_time"] / total) * 100
        else:
            compliance_data["sla_compliance_percentage"] = 100.0
        
        return compliance_data
    
    async def update_remediation_progress(
        self,
        vulnerability_id: str,
        progress_percentage: float,
        status_update: Optional[RemediationStatus] = None,
        notes: str = ""
    ) -> bool:
        """Update remediation progress for a vulnerability."""
        if vulnerability_id not in self.vulnerability_assessments:
            return False
        
        assessment = self.vulnerability_assessments[vulnerability_id]
        
        # Update progress
        old_status = assessment.remediation_status
        if status_update:
            assessment.remediation_status = status_update
        
        # Update timestamps for status changes
        now = datetime.now(timezone.utc)
        if old_status != assessment.remediation_status:
            if assessment.remediation_status == RemediationStatus.ASSIGNED:
                assessment.mean_time_to_assign = (now - assessment.first_seen).total_seconds() / 3600
            elif assessment.remediation_status == RemediationStatus.IN_PROGRESS:
                # Calculate time to start fix
                assessment.mean_time_to_fix = (now - assessment.first_seen).total_seconds() / 3600
            elif assessment.remediation_status in [RemediationStatus.RESOLVED, RemediationStatus.VERIFIED]:
                assessment.time_to_remediate_hours = (now - assessment.first_seen).total_seconds() / 3600
        
        # Add to audit trail
        audit_entry = {
            "timestamp": now.isoformat(),
            "action": "progress_update",
            "old_status": old_status.value,
            "new_status": assessment.remediation_status.value,
            "progress_percentage": progress_percentage,
            "notes": notes
        }
        assessment.audit_trail.append(audit_entry)
        
        # Log the update
        await self._log_remediation_progress_event(assessment, audit_entry)
        
        # Persist changes
        await self._persist_assessment(assessment)
        
        return True
    
    async def generate_executive_dashboard(self) -> Dict[str, Any]:
        """Generate executive-level vulnerability dashboard."""
        metrics = await self.get_vulnerability_metrics()
        sla_compliance = await self.check_sla_compliance()
        
        # Calculate trends (simplified - would use historical data in production)
        emergency_trend = "stable"  # Would calculate from historical data
        critical_trend = "increasing" if metrics.get("critical_vulnerabilities", 0) > 5 else "stable"
        
        # Calculate risk scores
        total_risk_score = 0.0
        risk_by_asset = defaultdict(float)
        
        for assessment in self.vulnerability_assessments.values():
            if assessment.remediation_status not in [RemediationStatus.RESOLVED, RemediationStatus.CLOSED]:
                total_risk_score += assessment.composite_priority_score
                asset_id = assessment.vulnerability_context.asset_id or "unknown"
                risk_by_asset[asset_id] += assessment.composite_priority_score
        
        # Top risk assets
        top_risk_assets = sorted(
            [(asset, risk) for asset, risk in risk_by_asset.items()],
            key=lambda x: x[1],
            reverse=True
        )[:5]
        
        dashboard = {
            "executive_summary": {
                "total_open_vulnerabilities": metrics.get("total_vulnerabilities", 0),
                "emergency_vulnerabilities": metrics.get("emergency_vulnerabilities", 0),
                "critical_vulnerabilities": metrics.get("critical_vulnerabilities", 0),
                "sla_compliance_percentage": sla_compliance.get("sla_compliance_percentage", 100),
                "sla_breaches": sla_compliance.get("breached", 0),
                "total_risk_score": round(total_risk_score, 2),
                "average_age_days": metrics.get("average_age_days", 0),
                "resolution_rate": metrics.get("resolution_rate_percentage", 0)
            },
            "trends": {
                "emergency_vulnerabilities": emergency_trend,
                "critical_vulnerabilities": critical_trend,
                "sla_compliance": "improving" if sla_compliance.get("sla_compliance_percentage", 0) > 90 else "declining"
            },
            "top_risks": {
                "assets_by_risk": [{"asset_id": asset, "risk_score": round(risk, 2)} for asset, risk in top_risk_assets],
                "urgent_actions_required": sla_compliance.get("breach_details", [])[:3],  # Top 3 breaches
                "escalations_pending": len(sla_compliance.get("escalation_details", []))
            },
            "business_impact": {
                "estimated_financial_exposure": sum(
                    a.business_impact.financial_impact for a in self.vulnerability_assessments.values()
                    if a.remediation_status not in [RemediationStatus.RESOLVED, RemediationStatus.CLOSED]
                ),
                "compliance_violations": len(set(
                    fw.value for a in self.vulnerability_assessments.values()
                    for fw in a.compliance_frameworks
                    if a.remediation_status not in [RemediationStatus.RESOLVED, RemediationStatus.CLOSED]
                )),
                "users_at_risk": sum(
                    a.business_impact.affected_users for a in self.vulnerability_assessments.values()
                    if a.remediation_status not in [RemediationStatus.RESOLVED, RemediationStatus.CLOSED]
                )
            },
            "recommendations": await self._generate_executive_recommendations(metrics, sla_compliance)
        }
        
        return dashboard
    
    async def _generate_executive_recommendations(
        self,
        metrics: Dict[str, Any],
        sla_compliance: Dict[str, Any]
    ) -> List[str]:
        """Generate executive-level recommendations."""
        recommendations = []
        
        # SLA compliance recommendations
        if sla_compliance.get("sla_compliance_percentage", 100) < 80:
            recommendations.append("URGENT: SLA compliance below 80%. Consider increasing security team capacity.")
        
        # Emergency vulnerability recommendations
        emergency_count = metrics.get("emergency_vulnerabilities", 0)
        if emergency_count > 0:
            recommendations.append(f"IMMEDIATE ACTION: {emergency_count} emergency vulnerabilities require 24-hour response.")
        
        # Critical vulnerability recommendations
        critical_count = metrics.get("critical_vulnerabilities", 0)
        if critical_count > 10:
            recommendations.append("Consider implementing emergency security patching procedures.")
        
        # Breach recommendations
        breach_count = sla_compliance.get("breached", 0)
        if breach_count > 0:
            recommendations.append(f"Address {breach_count} SLA-breached vulnerabilities to reduce organizational risk.")
        
        # General recommendations
        if metrics.get("average_age_days", 0) > 60:
            recommendations.append("High average vulnerability age indicates need for process optimization.")
        
        if metrics.get("resolution_rate_percentage", 0) < 70:
            recommendations.append("Low resolution rate suggests need for remediation process improvements.")
        
        recommendations.append("Schedule quarterly vulnerability assessment program review.")
        
        return recommendations
    
    async def export_compliance_report(
        self,
        framework: ComplianceFramework,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None
    ) -> Dict[str, Any]:
        """Export compliance-specific vulnerability report."""
        if start_date is None:
            start_date = datetime.now(timezone.utc) - timedelta(days=90)
        if end_date is None:
            end_date = datetime.now(timezone.utc)
        
        # Filter assessments by framework and date range
        relevant_assessments = []
        for assessment in self.vulnerability_assessments.values():
            if (framework in assessment.compliance_frameworks and
                start_date <= assessment.assessment_date <= end_date):
                relevant_assessments.append(assessment)
        
        # Generate framework-specific metrics
        report = {
            "framework": framework.value,
            "reporting_period": {
                "start_date": start_date.isoformat(),
                "end_date": end_date.isoformat()
            },
            "summary": {
                "total_violations": len(relevant_assessments),
                "critical_violations": len([a for a in relevant_assessments if a.priority_level == VulnerabilityPriority.CRITICAL]),
                "resolved_violations": len([a for a in relevant_assessments if a.remediation_status in [
                    RemediationStatus.RESOLVED, RemediationStatus.VERIFIED, RemediationStatus.CLOSED
                ]]),
                "open_violations": len([a for a in relevant_assessments if a.remediation_status in [
                    RemediationStatus.OPEN, RemediationStatus.ASSIGNED, RemediationStatus.IN_PROGRESS
                ]])
            },
            "detailed_findings": [],
            "remediation_status": defaultdict(int),
            "control_mappings": defaultdict(list)
        }
        
        for assessment in relevant_assessments:
            # Add detailed finding
            finding_detail = {
                "vulnerability_id": assessment.vulnerability_id,
                "vulnerability_type": assessment.source_finding.vulnerability_type,
                "severity": assessment.source_finding.severity.value,
                "cvss_score": assessment.cvss31_score.base_score,
                "asset_id": assessment.vulnerability_context.asset_id,
                "discovery_date": assessment.first_seen.isoformat(),
                "remediation_status": assessment.remediation_status.value,
                "due_date": assessment.due_date.isoformat(),
                "business_impact": assessment.business_impact.financial_impact
            }
            
            if assessment.remediation_status in [RemediationStatus.RESOLVED, RemediationStatus.VERIFIED]:
                finding_detail["resolution_date"] = assessment.verification_date.isoformat() if assessment.verification_date else "N/A"
                finding_detail["time_to_resolve_days"] = assessment.time_to_remediate_hours / 24
            
            report["detailed_findings"].append(finding_detail)
            
            # Count remediation statuses
            report["remediation_status"][assessment.remediation_status.value] += 1
            
            # Map to controls
            for control, mappings in assessment.control_mappings.items():
                report["control_mappings"][control].extend(mappings)
        
        # Calculate compliance score
        total_violations = report["summary"]["total_violations"]
        resolved_violations = report["summary"]["resolved_violations"]
        
        if total_violations > 0:
            compliance_score = (resolved_violations / total_violations) * 100
        else:
            compliance_score = 100.0
        
        report["compliance_score"] = round(compliance_score, 2)
        
        return report
    
    async def _log_remediation_progress_event(self, assessment: VulnerabilityAssessment, audit_entry: Dict[str, Any]):
        """Log remediation progress event."""
        try:
            audit_event = AuditEvent(
                event_id=str(uuid4()),
                timestamp=datetime.now(timezone.utc),
                event_type=AuditEventType.SECURITY_TEST_EXECUTED,
                severity=AuditSeverity.MEDIUM,
                user_id=None,
                session_id=None,
                resource_type="vulnerability_remediation",
                action="progress_update",
                result="SUCCESS",
                additional_data={
                    "vulnerability_id": assessment.vulnerability_id,
                    "old_status": audit_entry["old_status"],
                    "new_status": audit_entry["new_status"],
                    "progress_percentage": audit_entry["progress_percentage"],
                    "notes": audit_entry["notes"]
                }
            )
            
            await self.audit_logger.log_event(audit_event)
            
        except Exception as e:
            logger.error(f"Failed to log remediation progress event: {e}")
    
    async def get_vulnerability_metrics(self) -> Dict[str, Any]:
        """Get comprehensive vulnerability metrics."""
        assessments = list(self.vulnerability_assessments.values())
        
        if not assessments:
            return self.metrics
        
        # Current state metrics
        priority_counts = defaultdict(int)
        status_counts = defaultdict(int)
        age_distribution = []
        
        for assessment in assessments:
            priority_counts[assessment.priority_level.value] += 1
            status_counts[assessment.remediation_status.value] += 1
            age_days = (datetime.now(timezone.utc) - assessment.first_seen).days
            age_distribution.append(age_days)
            assessment.age_days = age_days
        
        # SLA compliance
        overdue_count = len([a for a in assessments if datetime.now(timezone.utc) > a.due_date])
        sla_compliance = ((len(assessments) - overdue_count) / len(assessments)) * 100
        
        # Remediation metrics
        resolved_assessments = [a for a in assessments if a.remediation_status in [
            RemediationStatus.RESOLVED, RemediationStatus.VERIFIED, RemediationStatus.CLOSED
        ]]
        
        remediation_times = [a.time_to_remediate_hours for a in resolved_assessments if a.time_to_remediate_hours > 0]
        
        metrics = {
            "total_vulnerabilities": len(assessments),
            "priority_distribution": dict(priority_counts),
            "status_distribution": dict(status_counts),
            "sla_compliance_percentage": sla_compliance,
            "overdue_vulnerabilities": overdue_count,
            "average_age_days": np.mean(age_distribution) if age_distribution else 0,
            "median_age_days": np.median(age_distribution) if age_distribution else 0,
            "resolved_vulnerabilities": len(resolved_assessments),
            "resolution_rate_percentage": (len(resolved_assessments) / len(assessments)) * 100,
            "average_remediation_time_hours": np.mean(remediation_times) if remediation_times else 0,
            "median_remediation_time_hours": np.median(remediation_times) if remediation_times else 0,
            "emergency_vulnerabilities": priority_counts["emergency"],
            "critical_vulnerabilities": priority_counts["critical"],
            "high_vulnerabilities": priority_counts["high"],
            "remediation_plans_active": len([p for p in self.remediation_plans.values() 
                                           if p.execution_status not in ["completed", "cancelled"]])
        }
        
        # Update stored metrics
        self.metrics.update(metrics)
        
        return metrics
    
    async def generate_vulnerability_report(
        self,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        priority_filter: Optional[List[VulnerabilityPriority]] = None
    ) -> Dict[str, Any]:
        """Generate comprehensive vulnerability assessment report."""
        if start_date is None:
            start_date = datetime.now(timezone.utc) - timedelta(days=30)
        if end_date is None:
            end_date = datetime.now(timezone.utc)
        
        # Filter assessments
        filtered_assessments = []
        for assessment in self.vulnerability_assessments.values():
            if start_date <= assessment.assessment_date <= end_date:
                if priority_filter is None or assessment.priority_level in priority_filter:
                    filtered_assessments.append(assessment)
        
        # Generate report
        report = {
            "report_metadata": {
                "generation_date": datetime.now(timezone.utc).isoformat(),
                "period_start": start_date.isoformat(),
                "period_end": end_date.isoformat(),
                "total_assessments": len(filtered_assessments)
            },
            "executive_summary": await self._generate_executive_summary(filtered_assessments),
            "vulnerability_trends": await self._analyze_vulnerability_trends(filtered_assessments),
            "priority_analysis": await self._analyze_priority_distribution(filtered_assessments),
            "remediation_performance": await self._analyze_remediation_performance(filtered_assessments),
            "compliance_status": await self._analyze_compliance_status(filtered_assessments),
            "recommendations": await self._generate_recommendations(filtered_assessments),
            "detailed_findings": [asdict(a) for a in filtered_assessments[:100]]  # Limit details
        }
        
        return report
    
    async def _generate_executive_summary(self, assessments: List[VulnerabilityAssessment]) -> str:
        """Generate executive summary for vulnerability report."""
        if not assessments:
            return "No vulnerabilities assessed in the reporting period."
        
        emergency_count = len([a for a in assessments if a.priority_level == VulnerabilityPriority.EMERGENCY])
        critical_count = len([a for a in assessments if a.priority_level == VulnerabilityPriority.CRITICAL])
        high_count = len([a for a in assessments if a.priority_level == VulnerabilityPriority.HIGH])
        
        overdue_count = len([a for a in assessments if datetime.now(timezone.utc) > a.due_date])
        
        summary = f"""
VULNERABILITY ASSESSMENT EXECUTIVE SUMMARY

Total Vulnerabilities Assessed: {len(assessments)}

CRITICAL FINDINGS:
- Emergency Priority: {emergency_count}
- Critical Priority: {critical_count}
- High Priority: {high_count}

SLA PERFORMANCE:
- Overdue Vulnerabilities: {overdue_count}
- SLA Compliance: {((len(assessments) - overdue_count) / len(assessments) * 100):.1f}%

IMMEDIATE ACTIONS REQUIRED:
"""
        
        if emergency_count > 0:
            summary += f"- Address {emergency_count} EMERGENCY vulnerabilities within 24 hours\n"
        
        if critical_count > 0:
            summary += f"- Remediate {critical_count} CRITICAL vulnerabilities within 72 hours\n"
        
        if overdue_count > 0:
            summary += f"- Prioritize {overdue_count} overdue vulnerabilities for immediate action\n"
        
        return summary.strip()
    
    async def _analyze_vulnerability_trends(self, assessments: List[VulnerabilityAssessment]) -> Dict[str, Any]:
        """Analyze vulnerability trends over time."""
        if not assessments:
            return {}
        
        # Group by week
        weekly_counts = defaultdict(int)
        weekly_critical = defaultdict(int)
        
        for assessment in assessments:
            week_key = assessment.assessment_date.strftime("%Y-W%U")
            weekly_counts[week_key] += 1
            if assessment.priority_level in [VulnerabilityPriority.EMERGENCY, VulnerabilityPriority.CRITICAL]:
                weekly_critical[week_key] += 1
        
        return {
            "weekly_discovery_trend": dict(weekly_counts),
            "weekly_critical_trend": dict(weekly_critical),
            "trend_analysis": "Trend analysis would include statistical analysis of discovery patterns"
        }
    
    async def _analyze_priority_distribution(self, assessments: List[VulnerabilityAssessment]) -> Dict[str, Any]:
        """Analyze priority distribution of vulnerabilities."""
        priority_counts = defaultdict(int)
        priority_percentages = {}
        
        for assessment in assessments:
            priority_counts[assessment.priority_level.value] += 1
        
        total = len(assessments)
        if total > 0:
            for priority, count in priority_counts.items():
                priority_percentages[priority] = (count / total) * 100
        
        return {
            "priority_counts": dict(priority_counts),
            "priority_percentages": priority_percentages,
            "distribution_analysis": "Analysis of priority distribution patterns and implications"
        }
    
    async def _analyze_remediation_performance(self, assessments: List[VulnerabilityAssessment]) -> Dict[str, Any]:
        """Analyze remediation performance metrics."""
        resolved_assessments = [a for a in assessments if a.remediation_status in [
            RemediationStatus.RESOLVED, RemediationStatus.VERIFIED, RemediationStatus.CLOSED
        ]]
        
        if not resolved_assessments:
            return {"message": "No resolved vulnerabilities in reporting period"}
        
        remediation_times = [a.time_to_remediate_hours for a in resolved_assessments if a.time_to_remediate_hours > 0]
        
        return {
            "total_resolved": len(resolved_assessments),
            "resolution_rate": (len(resolved_assessments) / len(assessments)) * 100,
            "average_remediation_time_hours": np.mean(remediation_times) if remediation_times else 0,
            "median_remediation_time_hours": np.median(remediation_times) if remediation_times else 0,
            "performance_analysis": "Performance trends and comparisons to benchmarks"
        }
    
    async def _analyze_compliance_status(self, assessments: List[VulnerabilityAssessment]) -> Dict[str, Any]:
        """Analyze compliance status across frameworks."""
        compliance_violations = defaultdict(int)
        
        for assessment in assessments:
            for violation in assessment.compliance_violations:
                compliance_violations[violation] += 1
        
        return {
            "compliance_violations": dict(compliance_violations),
            "compliance_score": "Overall compliance scoring would be calculated here",
            "regulatory_impact": "Analysis of regulatory implications"
        }
    
    async def _generate_recommendations(self, assessments: List[VulnerabilityAssessment]) -> List[str]:
        """Generate actionable recommendations."""
        recommendations = []
        
        emergency_count = len([a for a in assessments if a.priority_level == VulnerabilityPriority.EMERGENCY])
        critical_count = len([a for a in assessments if a.priority_level == VulnerabilityPriority.CRITICAL])
        overdue_count = len([a for a in assessments if datetime.now(timezone.utc) > a.due_date])
        
        if emergency_count > 0:
            recommendations.append(f"Immediately mobilize incident response team for {emergency_count} emergency vulnerabilities")
        
        if critical_count > 5:
            recommendations.append("Consider declaring a security incident and implementing emergency patching procedures")
        
        if overdue_count > 0:
            recommendations.append(f"Conduct remediation sprint to address {overdue_count} overdue vulnerabilities")
        
        # Analyze common vulnerability types
        vuln_types = [a.source_finding.vulnerability_type for a in assessments]
        type_counts = defaultdict(int)
        for vt in vuln_types:
            type_counts[vt] += 1
        
        most_common = max(type_counts.items(), key=lambda x: x[1]) if type_counts else None
        if most_common and most_common[1] > 3:
            recommendations.append(f"Focus security training on {most_common[0]} vulnerabilities (found {most_common[1]} times)")
        
        recommendations.append("Implement continuous vulnerability scanning to reduce discovery time")
        recommendations.append("Establish vulnerability disclosure program to improve external reporting")
        
        return recommendations
    
    async def _persist_assessment(self, assessment: VulnerabilityAssessment):
        """Persist vulnerability assessment to database."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT OR REPLACE INTO vulnerability_assessments (
                vulnerability_id, assessment_date, source_finding_data, cvss_score,
                epss_score, enterprise_risk_score, priority_level, remediation_status,
                assigned_to, due_date, context_data, created_date, updated_date
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            assessment.vulnerability_id,
            assessment.assessment_date.isoformat(),
            json.dumps(asdict(assessment.source_finding)),
            assessment.cvss_v3_score,
            assessment.epss_score,
            assessment.enterprise_risk_score,
            assessment.priority_level.value,
            assessment.remediation_status.value,
            assessment.assigned_to,
            assessment.due_date.isoformat(),
            json.dumps(asdict(assessment.vulnerability_context)),
            datetime.now(timezone.utc).isoformat(),
            datetime.now(timezone.utc).isoformat()
        ))
        
        conn.commit()
        conn.close()
    
    async def _persist_remediation_plan(self, plan: RemediationPlan):
        """Persist remediation plan to database."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT OR REPLACE INTO remediation_plans (
                plan_id, plan_name, priority, estimated_effort_hours, estimated_cost,
                planned_start_date, planned_completion_date, execution_status,
                progress_percentage, created_date, updated_date
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            plan.plan_id,
            plan.plan_name,
            plan.priority.value,
            plan.estimated_effort_hours,
            plan.estimated_cost,
            plan.planned_start_date.isoformat(),
            plan.planned_completion_date.isoformat(),
            plan.execution_status,
            plan.progress_percentage,
            datetime.now(timezone.utc).isoformat(),
            datetime.now(timezone.utc).isoformat()
        ))
        
        conn.commit()
        conn.close()
    
    async def _log_assessment_event(self, assessment: VulnerabilityAssessment):
        """Log vulnerability assessment event."""
        try:
            audit_event = AuditEvent(
                event_id=str(uuid4()),
                timestamp=datetime.now(timezone.utc),
                event_type=AuditEventType.SECURITY_TEST_EXECUTED,
                severity=AuditSeverity.HIGH if assessment.priority_level in [
                    VulnerabilityPriority.EMERGENCY, VulnerabilityPriority.CRITICAL
                ] else AuditSeverity.LOW,
                user_id=None,
                session_id=None,
                resource_type="vulnerability_assessment",
                action="vulnerability_assessed",
                result="SUCCESS",
                additional_data={
                    "vulnerability_id": assessment.vulnerability_id,
                    "priority_level": assessment.priority_level.value,
                    "cvss_score": assessment.cvss_v3_score,
                    "enterprise_risk_score": assessment.enterprise_risk_score,
                    "vulnerability_type": assessment.source_finding.vulnerability_type,
                    "asset_criticality": assessment.vulnerability_context.asset_criticality.value
                }
            )
            
            await self.audit_logger.log_event(audit_event)
            
        except Exception as e:
            logger.error(f"Failed to log assessment event: {e}")
    
    async def _log_remediation_plan_event(self, event_type: str, plan: RemediationPlan):
        """Log remediation plan event."""
        try:
            audit_event = AuditEvent(
                event_id=str(uuid4()),
                timestamp=datetime.now(timezone.utc),
                event_type=AuditEventType.SECURITY_TEST_EXECUTED,
                severity=AuditSeverity.MEDIUM,
                user_id=None,
                session_id=None,
                resource_type="remediation_plan",
                action=event_type.lower(),
                result="SUCCESS",
                additional_data={
                    "plan_id": plan.plan_id,
                    "plan_name": plan.plan_name,
                    "priority": plan.priority.value,
                    "vulnerability_count": len(plan.vulnerability_assessments),
                    "estimated_effort_hours": plan.estimated_effort_hours,
                    "estimated_cost": plan.estimated_cost
                }
            )
            
            await self.audit_logger.log_event(audit_event)
            
        except Exception as e:
            logger.error(f"Failed to log remediation plan event: {e}")
    
    async def _send_priority_alert(self, assessment: VulnerabilityAssessment):
        """Send alert for high-priority vulnerabilities."""
        try:
            severity = "critical" if assessment.priority_level == VulnerabilityPriority.EMERGENCY else "high"
            
            await self.real_time_alerting.send_alert(
                alert_type="high_priority_vulnerability",
                severity=severity,
                message=f"High-priority vulnerability detected: {assessment.source_finding.title}",
                context={
                    "vulnerability_id": assessment.vulnerability_id,
                    "priority_level": assessment.priority_level.value,
                    "cvss_score": assessment.cvss_v3_score,
                    "asset_id": assessment.vulnerability_context.asset_id,
                    "due_date": assessment.due_date.isoformat(),
                    "vulnerability_type": assessment.source_finding.vulnerability_type
                },
                priority=AlertPriority.URGENT if assessment.priority_level == VulnerabilityPriority.EMERGENCY else AlertPriority.HIGH
            )
            
        except Exception as e:
            logger.error(f"Failed to send priority alert: {e}")
    
    def _update_assessment_metrics(self, assessment: VulnerabilityAssessment):
        """Update vulnerability assessment metrics."""
        self.metrics["total_assessments"] += 1
        
        if assessment.priority_level == VulnerabilityPriority.EMERGENCY:
            self.metrics["emergency_vulnerabilities"] += 1
        elif assessment.priority_level == VulnerabilityPriority.CRITICAL:
            self.metrics["critical_vulnerabilities"] += 1
    
    async def health_check(self) -> Dict[str, Any]:
        """Perform health check of vulnerability assessment system."""
        health_status = {
            "status": "healthy",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "components": {},
            "metrics": await self.get_vulnerability_metrics()
        }
        
        try:
            # Check database connectivity
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM vulnerability_assessments")
            assessment_count = cursor.fetchone()[0]
            conn.close()
            
            health_status["components"]["database"] = "healthy"
            health_status["components"]["assessment_count"] = assessment_count
            
            # Check core components
            health_status["components"]["audit_logger"] = "available" if self.audit_logger else "unavailable"
            health_status["components"]["monitoring_system"] = "available" if self.monitoring_system else "unavailable"
            health_status["components"]["alerting_system"] = "available" if self.real_time_alerting else "unavailable"
            
        except Exception as e:
            health_status["status"] = "unhealthy"
            health_status["error"] = str(e)
        
        return health_status


# Factory function for creating vulnerability assessment framework
def create_vulnerability_assessment_framework(
    audit_logger: AuditLogger,
    monitoring_system: EnhancedMonitoringSystem,
    real_time_alerting: RealTimeAlerting
) -> VulnerabilityAssessmentFramework:
    """Create and initialize vulnerability assessment framework."""
    return VulnerabilityAssessmentFramework(
        audit_logger=audit_logger,
        monitoring_system=monitoring_system,
        real_time_alerting=real_time_alerting
    )


if __name__ == "__main__":
    # Example usage demonstrating advanced vulnerability assessment capabilities
    import asyncio
    from ..audits.audit_logger import AuditLogger
    from ..audits.enhanced_monitoring_system import EnhancedMonitoringSystem  
    from ..audits.real_time_alerting import RealTimeAlerting
    from .security_test_engine import SecurityFinding, SecuritySeverity
    
    async def demo_advanced_vulnerability_assessment():
        """Demonstrate advanced vulnerability assessment framework capabilities."""
        print("Advanced Vulnerability Assessment Framework Demo")
        print("=" * 50)
        
        # Initialize core components (mocked for demo)
        audit_logger = None  # Would be properly initialized in production
        monitoring_system = None  # Would be properly initialized in production
        alerting_system = None  # Would be properly initialized in production
        
        # Initialize framework
        framework = VulnerabilityAssessmentFramework(
            audit_logger, monitoring_system, alerting_system
        )
        
        # Example 1: Advanced CVSS 3.1 scoring
        print("\n1. Advanced CVSS 3.1 Scoring Example:")
        cvss_calc = CVSS31Calculator()
        
        # Create CVSS score for SQL injection
        cvss_score = CVSS31Score()
        cvss_score.base_metrics.attack_vector = AttackVector.NETWORK
        cvss_score.base_metrics.attack_complexity = AttackComplexity.LOW
        cvss_score.base_metrics.privileges_required = PrivilegesRequired.NONE
        cvss_score.base_metrics.user_interaction = UserInteraction.NONE
        cvss_score.base_metrics.scope = Scope.UNCHANGED
        cvss_score.base_metrics.confidentiality_impact = Impact.HIGH
        cvss_score.base_metrics.integrity_impact = Impact.HIGH
        cvss_score.base_metrics.availability_impact = Impact.NONE
        
        calculated_score = cvss_calc.calculate_cvss31_score(cvss_score)
        print(f"   SQL Injection CVSS 3.1 Base Score: {calculated_score.base_score}")
        print(f"   Vector String: {calculated_score.vector_string}")
        print(f"   Severity: {calculated_score.base_severity}")
        
        # Example 2: EPSS Integration
        print("\n2. EPSS Integration Example:")
        epss_integration = EPSSIntegration()
        
        # Simulate EPSS score categorization
        test_scores = [0.05, 0.25, 0.45, 0.75, 0.95]
        for score in test_scores:
            level = epss_integration._categorize_epss_score(score)
            print(f"   EPSS Score {score}: {level.value}")
        
        # Example 3: Business Impact Assessment
        print("\n3. Business Impact Assessment Example:")
        business_calc = BusinessImpactCalculator()
        
        # Create sample vulnerability assessment
        sample_finding = SecurityFinding(
            finding_id="DEMO-001",
            title="Critical SQL Injection in Login Form",
            description="SQL injection vulnerability in user authentication",
            severity=SecuritySeverity.CRITICAL,
            vulnerability_type="sql_injection",
            cve_id="CVE-2023-DEMO"
        )
        
        context = VulnerabilityContext(
            asset_id="web-app-01",
            asset_name="Customer Portal",
            asset_criticality=AssetCriticality.CRITICAL,
            network_exposure="external",
            data_sensitivity="high"
        )
        
        assessment = VulnerabilityAssessment(
            source_finding=sample_finding,
            vulnerability_context=context
        )
        
        # Calculate business impact (async call would be awaited in real usage)
        print("   Business Impact Assessment calculated (demo)")
        print(f"   Asset Criticality: {context.asset_criticality.value}")
        print(f"   Network Exposure: {context.network_exposure}")
        print(f"   Data Sensitivity: {context.data_sensitivity}")
        
        # Example 4: Comprehensive Assessment
        print("\n4. Comprehensive Assessment Example:")
        print("   Assessment ID:", assessment.vulnerability_id)
        print("   Priority Level:", assessment.priority_level.value)
        print("   SLA Hours:", assessment.remediation_sla_hours)
        
        # Example 5: Compliance Framework Mapping
        print("\n5. Compliance Framework Mapping:")
        frameworks = [ComplianceFramework.PCI_DSS, ComplianceFramework.SOC2, ComplianceFramework.NIST_800_53]
        for framework in frameworks:
            print(f"   {framework.value}: Applicable for SQL injection vulnerabilities")
        
        print("\n6. Advanced Features Available:")
        print("    Real-time EPSS scoring integration")
        print("    Comprehensive business impact assessment")
        print("    Advanced SLA tracking with escalation")
        print("    Multi-framework compliance reporting")
        print("    Executive dashboard generation")
        print("    Automated remediation planning")
        print("    Cost-benefit analysis")
        print("    Risk-based prioritization")
        
        print("\nFramework ready for enterprise deployment!")
        print("Refer to method documentation for integration details.")
    
    # Note: This would be run with asyncio.run(demo_advanced_vulnerability_assessment()) 
    # in a proper async context
    print("Advanced Vulnerability Assessment Framework")
    print("Run demo_advanced_vulnerability_assessment() in an async context for examples")
    print("\nKey capabilities:")
    print("- CVSS 3.1 compliant scoring with temporal and environmental metrics")
    print("- Real-time EPSS integration for exploit probability assessment")
    print("- Comprehensive business impact assessment with financial modeling")
    print("- Advanced SLA tracking with automated escalation")
    print("- Multi-framework compliance reporting (NIST, PCI-DSS, FedRAMP, etc.)")
    print("- Executive dashboards and risk analytics")
    print("- Automated remediation planning with resource allocation")
    print("- Integration with existing security-compliance infrastructure")